{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import sys \n",
    "import pandas as pd\n",
    "import os\n",
    "import optuna\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchcontrib.optim import SWA\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from argparse import ArgumentParser\n",
    "sys.path.append('../data/')\n",
    "sys.path.append('../data/ml_mmrf')\n",
    "sys.path.append('../data/synthetic')\n",
    "sys.path.append('../data/semi_synthetic')\n",
    "sys.path.append('../ief_core/')\n",
    "sys.path.append('../ief_core/models/')\n",
    "from ml_mmrf.ml_mmrf_v1.data import load_mmrf\n",
    "from synthetic_data import load_synthetic_data_trt, load_synthetic_data_noisy\n",
    "from ss_data import *\n",
    "from models.ssm.ssm import SSM, SSMAtt\n",
    "from models.ssm.ssm_baseline import SSMBaseline\n",
    "from models.rnn import GRU\n",
    "from models.utils import *\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## alternate font/graph format\n",
    "plt.rcParams['ps.useafm'] = True\n",
    "plt.rcParams['pdf.use14corefonts'] = True\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rc('font', weight='heavy')\n",
    "plt.rc('xtick', labelsize='x-large')\n",
    "plt.rc('ytick', labelsize='x-large')\n",
    "plt.rc('axes', labelsize='x-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device  = torch.device('cpu')\n",
    "fname = '../ief_core/tests/checkpoints/ssm_semi_syn_moe_20000sample_complexityepoch=00989-val_loss=-323.60.ckpt'\n",
    "\n",
    "checkpoint = torch.load(fname, map_location=lambda storage, loc: storage)\n",
    "hparams    = checkpoint['hyper_parameters']\n",
    "del hparams['trial']\n",
    "print({'bs': hparams.bs, 'lr': hparams.lr, 'C': hparams.C, 'reg_all': hparams.reg_all, 'reg_type': hparams.reg_type, 'dim_stochastic': hparams.dim_stochastic})\n",
    "trial = optuna.trial.FixedTrial({'bs': hparams.bs, 'lr': hparams.lr, 'C': hparams.C, 'reg_all': hparams.reg_all, 'reg_type': hparams.reg_type, 'dim_stochastic': hparams.dim_stochastic})\n",
    "model = SSM(trial, **hparams); model.setup(1)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.to(device)\n",
    "print(model.hparams.ss_in_sample_dist)\n",
    "print(model.hparams.ss_missing)\n",
    "ddata = load_ss_data(1000, gen_fly=True, eval_mult=200, in_sample_dist=model.hparams.ss_in_sample_dist, add_missing=model.hparams.ss_missing)\n",
    "print(f'eval set size: {ddata[\"valid\"][0][\"X\"].shape}')\n",
    "nelbos = []\n",
    "for i in range(1,5):\n",
    "    _, valid_loader = load_ss_helper(ddata, tvt='valid', bs=model.hparams['bs'], device=device, valid_fold=i)\n",
    "    batch_nelbos = []\n",
    "    for i_batch, valid_batch_loader in enumerate(valid_loader):\n",
    "        (nelbo, nll, kl, _), _ = model.forward(*valid_batch_loader, anneal = 1.)\n",
    "        nelbo, nll, kl         = nelbo.item(), nll.item(), kl.item()\n",
    "        batch_nelbos.append(nelbo)\n",
    "    # (nelbo, nll, kl, _), _ = model.forward(*valid_loader.dataset.tensors, anneal = 1.)\n",
    "    nelbos.append(np.mean(batch_nelbos))\n",
    "print(f'[COMPLETE] mean nelbo: {np.mean(nelbos)}, std nelbo: {np.std(nelbos)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.polynomial.polynomial import polyval\n",
    "np.random.seed(0)\n",
    "def g(v, params=None): \n",
    "    if params is not None: \n",
    "        a1, a2, a3, b, gamma = params \n",
    "    else: \n",
    "        a1 = 5; a2 = 0.3; a3 = 0.4; b = 2; gamma = 40.\n",
    "    b0 = -a1 / (1 + np.exp(a2*gamma / 2))\n",
    "    a0 = (a1 + 2*b0 - b) / (1 + np.exp(-a3*gamma/2))\n",
    "    if v < gamma: \n",
    "        return b0 + a1 / (1 + np.exp(-a2*(v-(gamma/2))))\n",
    "    else: \n",
    "        return b + a0 / (1 + np.exp(a3*(v-(3*gamma)/2)))\n",
    "params = [-15, 0.7, 0.4, 2, 3]\n",
    "params2 = [5, 0.1, 0.3, 2, 2]\n",
    "Xvals = np.arange(20)\n",
    "up    = [-2, 0.0002, 0.1]\n",
    "res   = np.array([polyval(val,up) for val in Xvals]) \n",
    "res   = 0.5*res+0.5*np.random.randn(*res.shape)\n",
    "rx_t  = np.arange(8,14)\n",
    "res_copy = np.copy(res)\n",
    "for t in rx_t: \n",
    "    re = np.arange(Xvals.shape[0] - t)\n",
    "    add = np.array([g(v,params) for v in re])\n",
    "    res_copy[np.arange(t,Xvals.shape[0])]+= add\n",
    "fig, ax = plt.subplots(figsize=(8,5.2))\n",
    "ax.plot(Xvals, res, color='blue', linestyle='-', label='baseline')\n",
    "ax.plot(Xvals, res_copy, color='red', linestyle='-.', label='baseline+trt resp')\n",
    "for t in range(len(rx_t)): \n",
    "    if t == 0:\n",
    "        ax.axvline(rx_t[t], linestyle=':', color='grey', label='treatment')\n",
    "    else: \n",
    "        ax.axvline(rx_t[t], linestyle=':', color='grey')\n",
    "#            ax.set_xlabel('Time', fontsize=18)\n",
    "ax.tick_params(labelsize=20)\n",
    "ax.set_xlabel('Time', fontsize=25)\n",
    "ax.set_ylabel('Z', fontsize=25)\n",
    "ax.legend(fontsize=20)\n",
    "# plt.title('Baseline Progression w/ Superimposed Treatment Response', fontsize=15, pad=15)\n",
    "fig.savefig('./plots/treatment_exp_syn.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples        = {'train':100, 'valid':1000, 'test':50000}\n",
    "folds           = [0,1,2,3,4]\n",
    "alpha_1_complex = False; per_missing = 0.; add_feat = 0; num_trt = 1\n",
    "ddata = load_synthetic_data_trt(fold_span = folds, \\\n",
    "                                nsamples = nsamples, \\\n",
    "                                distractor_dims_b=4, \\\n",
    "                                sigma_ys=0.7, \\\n",
    "                                include_line=True, \\\n",
    "                                alpha_1_complex=alpha_1_complex, \\\n",
    "                                per_missing=per_missing, \\\n",
    "                                add_feats=add_feat, \\\n",
    "                                num_trt=num_trt, \\\n",
    "                                sub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_torch_dataset(ddata, fold, tvt, device=None, oversample=True, att_mask=False, batch_size=600):\n",
    "    if device is not None: \n",
    "        B  = torch.from_numpy(ddata[fold][tvt]['b'].astype('float32')).to(device)\n",
    "        X  = torch.from_numpy(ddata[fold][tvt]['x'].astype('float32')).to(device)\n",
    "        A  = torch.from_numpy(ddata[fold][tvt]['a'].astype('float32')).to(device)\n",
    "        M  = torch.from_numpy(ddata[fold][tvt]['m'].astype('float32')).to(device)\n",
    "    else: \n",
    "        B  = torch.from_numpy(ddata[fold][tvt]['b'].astype('float32'))\n",
    "        X  = torch.from_numpy(ddata[fold][tvt]['x'].astype('float32'))\n",
    "        A  = torch.from_numpy(ddata[fold][tvt]['a'].astype('float32'))\n",
    "        M  = torch.from_numpy(ddata[fold][tvt]['m'].astype('float32'))\n",
    "\n",
    "    y_vals   = ddata[fold][tvt]['ys_seq'][:,0].astype('float32')\n",
    "    idx_sort = np.argsort(y_vals)\n",
    "\n",
    "    if 'digitized_y' in ddata[fold][tvt]:\n",
    "        print ('using digitized y')\n",
    "        Y  = torch.from_numpy(ddata[fold][tvt]['digitized_y'].astype('float32'))\n",
    "    else:\n",
    "        Y  = torch.from_numpy(ddata[fold][tvt]['ys_seq'][:,[0]]).squeeze()\n",
    "\n",
    "    if device is not None: \n",
    "        Y = Y.to(device)\n",
    "        CE = torch.from_numpy(ddata[fold][tvt]['ce'].astype('float32')).to(device)\n",
    "    else: \n",
    "        CE = torch.from_numpy(ddata[fold][tvt]['ce'].astype('float32'))\n",
    "\n",
    "    if att_mask: \n",
    "        attn_shape  = (A.shape[0],A.shape[1],A.shape[1])\n",
    "        Am   = get_attn_mask(attn_shape, ddata[fold][tvt]['a'].astype('float32'), device)\n",
    "        data = TensorDataset(B[idx_sort], X[idx_sort], A[idx_sort], M[idx_sort], Y[idx_sort], CE[idx_sort], Am[idx_sort])\n",
    "    else: \n",
    "        data = TensorDataset(B[idx_sort], X[idx_sort], A[idx_sort], M[idx_sort], Y[idx_sort], CE[idx_sort])\n",
    "    data_loader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    return data, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sname = {}; models = {}\n",
    "# sname['syn_ssm_lin'] = '../ief_core/tests/checkpoints/ssm_syn_lin500samp_epoch=14941-val_loss=58.03.ckpt'\n",
    "# sname['syn_ssm_nl'] = '../ief_core/tests/checkpoints/ssm_syn_nl500samp_epoch=07918-val_loss=68.33.ckpt'\n",
    "# sname['syn_ssm_att'] = '../ief_core/tests/checkpoints/ssm_syn_attn_transitionepoch=10412-val_loss=54.43.ckpt'\n",
    "# sname['syn_ssm_att_nolc'] = '../ief_core/tests/checkpoints/ssm_syn_nolcepoch=14845-val_loss=38.09.ckpt'\n",
    "sname['syn_ssm_att_notexp'] = '../ief_core/tests/checkpoints/ssm_syn_attn_transitionnotrtexpepoch=07733-val_loss=58.16.ckpt'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device  = torch.device('cpu')\n",
    "    \n",
    "for model_n in sname.keys(): \n",
    "    checkpoint = torch.load(sname[model_n], map_location=lambda storage, loc: storage)\n",
    "    hparams    = checkpoint['hyper_parameters']\n",
    "    del hparams['trial']\n",
    "    \n",
    "    trial = optuna.trial.FixedTrial({'bs': hparams.bs, 'lr': hparams.lr, 'C': hparams.C, 'reg_all': hparams.reg_all, 'reg_type': hparams.reg_type, 'dim_stochastic': hparams.dim_stochastic})\n",
    "    model = SSM(trial, **hparams); model.setup(1)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    models[model_n] = model\n",
    "    models[model_n].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [0,1,2,3,4]\n",
    "for model_ in models: \n",
    "    model = models[model_]\n",
    "    fold_nelbos = []\n",
    "    for fold in folds: \n",
    "        data, data_loader = setup_torch_dataset(ddata, fold, 'test', device)\n",
    "\n",
    "        batch_nelbos = []\n",
    "        model.eval()\n",
    "        for i_batch, data_batch_loader in enumerate(data_loader):\n",
    "            (nelbo, nll, kl, _), _ = model.forward(*data_batch_loader, anneal = 1.)\n",
    "            nelbo, nll, kl         = nelbo.item(), nll.item(), kl.item()\n",
    "            batch_nelbos.append(nelbo)\n",
    "        fold_nelbos.append(np.mean(batch_nelbos))\n",
    "\n",
    "    print('stats for %s'%model_)\n",
    "    print('mean NELBO:', np.mean(fold_nelbos))\n",
    "    print('std NELBO:', np.std(fold_nelbos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 1\n",
    "data, data_loader = setup_torch_dataset(ddata, fold, 'valid', device)\n",
    "subtype  = ddata[fold]['valid']['subtype']\n",
    "y_vals   = ddata[fold]['valid']['ys_seq'][:,0].astype('float32').ravel()\n",
    "idx_sort = np.argsort(y_vals)\n",
    "sorted_subtype = subtype[idx_sort]\n",
    "sorted_ys = y_vals[idx_sort]\n",
    "sorted_xs = ddata[fold]['valid']['x'][idx_sort]\n",
    "sorted_as = ddata[fold]['valid']['a'][idx_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(B, X, A, M, Y, CE) = data_loader.dataset.tensors\n",
    "_, _, lens = get_masks(M)\n",
    "# T_forward  = 10; T_condition = 5\n",
    "T_forward = 17; T_condition = 2\n",
    "# B, X, A, M, Y, CE = B[lens>T_forward+T_condition], X[lens>T_forward+T_condition], A[lens>T_forward+T_condition], M[lens>T_forward+T_condition], Y[lens>T_forward+T_condition], CE[lens>T_forward+T_condition]\n",
    "\n",
    "samples = {}\n",
    "for name, model in models.items():\n",
    "    _, _, _, _, _, tforward = model.inspect(T_forward, T_condition, B, X, A, M, Y, CE)\n",
    "    tforw_n = tforward.cpu().detach().numpy()\n",
    "    samples[name] = tforw_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "fig, axlist = plt.subplots(1,2,figsize=(12,5))\n",
    "scolor=get_scolor()\n",
    "fig.subplots_adjust(hspace = 0.4)\n",
    "\n",
    "model_name  = 'PK-PD'\n",
    "model_name2  = 'Linear'\n",
    "model_name3  = 'PK-PD w/o lc'\n",
    "tvt = 'valid'\n",
    "pidx = 0\n",
    "k2alph = {}\n",
    "k2alph[0] = '(a)'\n",
    "k2alph[1] = '(b)'\n",
    "k2alph[2] = '(c)'\n",
    "k2alph[3] = '(d)'\n",
    "pt = 3\n",
    "ks = [1]\n",
    "axs = axlist.ravel()\n",
    "\n",
    "for k, ax in enumerate([axs[0]]):    \n",
    "    idx   = np.where(sorted_subtype==ks[k])[0]\n",
    "    pred  = samples['syn_ssm_att_notexp'][idx[pt]]\n",
    "    pred2 = samples['syn_ssm_lin'][idx[pt]]\n",
    "    pred3 = samples['syn_ssm_att_nolc'][idx[pt]]\n",
    "    \n",
    "    data   = sorted_xs[idx[pt],:,:]\n",
    "    trt_idx= np.where(sorted_as[idx[pt],:,1] == 1.)[0][0]\n",
    "    xvals  = np.arange(data.shape[0])\n",
    "    \n",
    "    tlist_x = []; tlist_y = []\n",
    "    treat_i = sorted_as[idx[pt],:,1]\n",
    "    ymax = ax.get_ylim()[1]+0.05\n",
    "    for t in range(treat_i.shape[0]):\n",
    "        if treat_i[t] == 1:\n",
    "            tlist_x.append(t)\n",
    "            tlist_y.append(15)\n",
    "    line1 = ax.scatter(tlist_x, tlist_y, marker='v', color='orange')\n",
    "    line2 = ax.fill_between(tlist_x, np.array(tlist_y)+4, np.array(tlist_y)+6, color='darkred', alpha=0.7)\n",
    "    \n",
    "    ax.annotate('Line', xy=(40, 247), xycoords='axes points',\n",
    "            size=20, bbox=dict(boxstyle='round', fc='w'))\n",
    "    ax.annotate('Trt', xy=(45, 217), xycoords='axes points',\n",
    "            size=20, bbox=dict(boxstyle='round', fc='w'))\n",
    "\n",
    "    ax.scatter(xvals, data[:,0], s = 64, label = 'Data')\n",
    "    ax.plot(xvals[1:18], pred[:,0],'o-', color='k', label = '%s'%(model_name), linewidth=3., alpha=0.5, markersize=8)\n",
    "    ax.plot(xvals[1:18], pred2[:,0],'x-', color='r', label = '%s'%(model_name2), linewidth=3., alpha=0.5, markersize=8)\n",
    "    ax.plot(xvals[1:18], pred3[:,0],'^-', color='darkgrey', label = '%s'%(model_name3), linewidth=3., markersize=8)\n",
    "    tag = 'S[%d]'%(ks[k])\n",
    "    ax.set_title('Patient [%d] (Biomarker 1)'%(ks[k]), fontsize=25, pad=10)\n",
    "    ax.set_xlabel('Time', fontsize=25)\n",
    "    ax.tick_params(labelsize=20)\n",
    "    if k == 0: \n",
    "        ax.legend(fontsize=17, loc=3)\n",
    "\n",
    "for k, ax in enumerate([axs[1]]): \n",
    "    idx   = np.where(sorted_subtype==ks[k])[0]\n",
    "    pred  = samples['syn_ssm_att_notexp'][idx[pt]]\n",
    "    pred2 = samples['syn_ssm_lin'][idx[pt]]\n",
    "    pred3 = samples['syn_ssm_att_nolc'][idx[pt]]\n",
    "    data  = sorted_xs[idx[pt],:,:]\n",
    "    xvals = np.arange(data.shape[0])\n",
    "    trt_idx= np.where(sorted_as[idx[pt],:,1] == 1.)[0][0]\n",
    "    \n",
    "    tlist_x = []; tlist_y = []\n",
    "    treat_i = sorted_as[idx[pt],:,1]\n",
    "    for t in range(treat_i.shape[0]):\n",
    "        if treat_i[t] == 1:\n",
    "            tlist_x.append(t)\n",
    "            tlist_y.append(32)\n",
    "    ax.scatter(tlist_x, tlist_y, marker='v', color='orange')\n",
    "    ax.fill_between(tlist_x, np.array(tlist_y)+4, np.array(tlist_y)+6, color='darkred', alpha=0.7)\n",
    "    \n",
    "    bidx = 2\n",
    "    ax.scatter(xvals, data[:,1], label = 'Data', s=64)\n",
    "    ax.plot(xvals[1:18], pred[:,1],'o-', color='k', label = '%s'%(model_name), linewidth=3., alpha=0.5, markersize=8)\n",
    "    ax.plot(xvals[1:18], pred2[:,1],'x-', color='r', label = '%s'%(model_name2), linewidth=3., alpha=0.5, markersize=8)\n",
    "    ax.plot(xvals[1:18], pred3[:,1],'^-', color='darkgrey', label = '%s'%(model_name3), linewidth=3., markersize=8)\n",
    "    tag = 'S[%d]'%(ks[k])\n",
    "    ax.set_title('Patient [%d] (Biomarker %d)'%(ks[k],bidx), fontsize=25, pad=10)\n",
    "    ax.set_xlabel('Time', fontsize=25)\n",
    "    ax.tick_params(labelsize=20)\n",
    "    \n",
    "plt.savefig('./plots/aaai-plots/ssm_syn_joint24_bigfonts_nolc_linetrt.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from: /afs/csail.mit.edu/u/z/zeshanmh/research/ief/data/ml_mmrf/ml_mmrf/ml_mmrf_v1/cleaned_mm_fold_2mos.pkl\n",
      "Digitizing outcomes ymax: 35.81666666666667\n",
      "19 20 20\n",
      "dict_keys(['ssm-lin-fold1', 'ssm-att-fold1'])\n",
      "all\n",
      "ssm-lin-fold1\n",
      "\"C\":                              0.01\n",
      "\"accumulate_grad_batches\":        1\n",
      "\"add_stochastic\":                 False\n",
      "\"alpha1_type\":                    linear\n",
      "\"amp_level\":                      O2\n",
      "\"anneal\":                         1\n",
      "\"att_mask\":                       False\n",
      "\"augmented\":                      False\n",
      "\"auto_lr_find\":                   False\n",
      "\"auto_scale_batch_size\":          False\n",
      "\"auto_select_gpus\":               False\n",
      "\"benchmark\":                      False\n",
      "\"bs\":                             600\n",
      "\"check_val_every_n_epoch\":        1\n",
      "\"checkpoint_callback\":            True\n",
      "\"combiner_type\":                  pog\n",
      "\"dataset\":                        mm\n",
      "\"default_root_dir\":               None\n",
      "\"deterministic\":                  False\n",
      "\"dim_base\":                       16\n",
      "\"dim_data\":                       16\n",
      "\"dim_hidden\":                     300\n",
      "\"dim_stochastic\":                 16\n",
      "\"dim_treat\":                      9\n",
      "\"distributed_backend\":            None\n",
      "\"early_stop_callback\":            False\n",
      "\"elbo_samples\":                   1\n",
      "\"etype\":                          lin\n",
      "\"eval_type\":                      nelbo\n",
      "\"fast_dev_run\":                   False\n",
      "\"fname\":                          None\n",
      "\"fold\":                           1\n",
      "\"gradient_clip_val\":              0\n",
      "\"imp_sampling\":                   False\n",
      "\"include_baseline\":               all\n",
      "\"inftype\":                        rnn_relu\n",
      "\"limit_test_batches\":             1.0\n",
      "\"limit_train_batches\":            1.0\n",
      "\"limit_val_batches\":              1.0\n",
      "\"log_gpu_memory\":                 None\n",
      "\"log_save_interval\":              100\n",
      "\"logger\":                         True\n",
      "\"loss_type\":                      unsup\n",
      "\"lr\":                             0.001\n",
      "\"max_epochs\":                     15000\n",
      "\"max_steps\":                      None\n",
      "\"min_epochs\":                     1\n",
      "\"min_steps\":                      None\n",
      "\"model_name\":                     ssm\n",
      "\"nheads\":                         1\n",
      "\"nsamples\":                       1\n",
      "\"nsamples_syn\":                   100\n",
      "\"num_nodes\":                      1\n",
      "\"num_processes\":                  1\n",
      "\"num_sanity_val_steps\":           2\n",
      "\"optimizer_name\":                 adam\n",
      "\"otype\":                          linear\n",
      "\"overfit_batches\":                0.0\n",
      "\"overfit_pct\":                    None\n",
      "\"post_approx\":                    diag\n",
      "\"precision\":                      32\n",
      "\"prepare_data_per_node\":          True\n",
      "\"print_nan_grads\":                False\n",
      "\"process_position\":               0\n",
      "\"profiler\":                       None\n",
      "\"progress_bar_refresh_rate\":      1\n",
      "\"rank\":                           5\n",
      "\"reg_all\":                        True\n",
      "\"reg_type\":                       l1\n",
      "\"reload_dataloaders_every_epoch\": False\n",
      "\"replace_sampler_ddp\":            True\n",
      "\"resume_from_checkpoint\":         None\n",
      "\"row_log_interval\":               50\n",
      "\"ss_in_sample_dist\":              False\n",
      "\"ss_missing\":                     False\n",
      "\"terminate_on_nan\":               False\n",
      "\"test_percent_check\":             None\n",
      "\"track_grad_norm\":                -1\n",
      "\"train_percent_check\":            None\n",
      "\"trial\":                          <optuna.trial._fixed.FixedTrial object at 0x7f65c26d6588>\n",
      "\"truncated_bptt_steps\":           None\n",
      "\"ttype\":                          lin\n",
      "\"val_check_interval\":             1.0\n",
      "\"val_percent_check\":              None\n",
      "\"weights_save_path\":              None\n",
      "\"weights_summary\":                top\n",
      "loading from: /afs/csail.mit.edu/u/z/zeshanmh/research/ief/data/ml_mmrf/ml_mmrf/ml_mmrf_v1/cleaned_mm_fold_2mos.pkl\n",
      "Digitizing outcomes ymax: 35.81666666666667\n",
      "19 20 20\n",
      "using relu in inf. network\n",
      "iss\n",
      "ssm-att-fold1\n",
      "\"C\":                              0.01\n",
      "\"accumulate_grad_batches\":        1\n",
      "\"add_stochastic\":                 False\n",
      "\"alpha1_type\":                    linear\n",
      "\"amp_level\":                      O2\n",
      "\"anneal\":                         1\n",
      "\"att_mask\":                       False\n",
      "\"augmented\":                      False\n",
      "\"auto_lr_find\":                   False\n",
      "\"auto_scale_batch_size\":          False\n",
      "\"auto_select_gpus\":               False\n",
      "\"benchmark\":                      False\n",
      "\"bs\":                             600\n",
      "\"check_val_every_n_epoch\":        1\n",
      "\"checkpoint_callback\":            True\n",
      "\"combiner_type\":                  pog\n",
      "\"dataset\":                        mm\n",
      "\"default_root_dir\":               None\n",
      "\"deterministic\":                  False\n",
      "\"dim_base\":                       16\n",
      "\"dim_data\":                       16\n",
      "\"dim_hidden\":                     300\n",
      "\"dim_stochastic\":                 48\n",
      "\"dim_treat\":                      9\n",
      "\"distributed_backend\":            None\n",
      "\"early_stop_callback\":            False\n",
      "\"elbo_samples\":                   1\n",
      "\"etype\":                          lin\n",
      "\"eval_type\":                      nelbo\n",
      "\"fast_dev_run\":                   False\n",
      "\"fname\":                          None\n",
      "\"fold\":                           1\n",
      "\"gradient_clip_val\":              0\n",
      "\"imp_sampling\":                   False\n",
      "\"include_baseline\":               iss\n",
      "\"include_baseline_inf\":           all\n",
      "\"inftype\":                        rnn_relu\n",
      "\"limit_test_batches\":             1.0\n",
      "\"limit_train_batches\":            1.0\n",
      "\"limit_val_batches\":              1.0\n",
      "\"log_gpu_memory\":                 None\n",
      "\"log_save_interval\":              100\n",
      "\"logger\":                         True\n",
      "\"loss_type\":                      semisup\n",
      "\"lr\":                             0.001\n",
      "\"max_epochs\":                     15000\n",
      "\"max_steps\":                      None\n",
      "\"min_epochs\":                     1\n",
      "\"min_steps\":                      None\n",
      "\"model_name\":                     ssm\n",
      "\"nheads\":                         1\n",
      "\"nsamples\":                       1\n",
      "\"nsamples_syn\":                   100\n",
      "\"num_nodes\":                      1\n",
      "\"num_processes\":                  1\n",
      "\"num_sanity_val_steps\":           2\n",
      "\"optimizer_name\":                 adam\n",
      "\"otype\":                          linear\n",
      "\"overfit_batches\":                0.0\n",
      "\"overfit_pct\":                    None\n",
      "\"post_approx\":                    diag\n",
      "\"precision\":                      32\n",
      "\"prepare_data_per_node\":          True\n",
      "\"print_nan_grads\":                False\n",
      "\"process_position\":               0\n",
      "\"profiler\":                       None\n",
      "\"progress_bar_refresh_rate\":      1\n",
      "\"rank\":                           5\n",
      "\"reg_all\":                        True\n",
      "\"reg_type\":                       l1\n",
      "\"reload_dataloaders_every_epoch\": False\n",
      "\"replace_sampler_ddp\":            True\n",
      "\"resume_from_checkpoint\":         None\n",
      "\"row_log_interval\":               50\n",
      "\"ss_in_sample_dist\":              False\n",
      "\"ss_missing\":                     False\n",
      "\"terminate_on_nan\":               False\n",
      "\"test_percent_check\":             None\n",
      "\"track_grad_norm\":                -1\n",
      "\"train_percent_check\":            None\n",
      "\"trial\":                          <optuna.trial._fixed.FixedTrial object at 0x7f659de6dfd0>\n",
      "\"truncated_bptt_steps\":           None\n",
      "\"ttype\":                          attn_transition\n",
      "\"val_check_interval\":             1.0\n",
      "\"val_percent_check\":              None\n",
      "\"weights_save_path\":              None\n",
      "\"weights_summary\":                top\n",
      "loading from: /afs/csail.mit.edu/u/z/zeshanmh/research/ief/data/ml_mmrf/ml_mmrf/ml_mmrf_v1/cleaned_mm_fold_2mos.pkl\n",
      "Digitizing outcomes ymax: 35.81666666666667\n",
      "19 20 20\n",
      "using relu in inf. network\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SSM:\n\tsize mismatch for transition_fxn.t_mu.control_layer.weight: copying a param with shape torch.Size([48, 25]) from checkpoint, the shape in current model is torch.Size([48, 14]).\n\tsize mismatch for transition_fxn.t_mu.logcell.controlfxn.weight: copying a param with shape torch.Size([48, 24]) from checkpoint, the shape in current model is torch.Size([48, 13]).\n\tsize mismatch for transition_fxn.t_mu.treatment_exp.alpha_1_layer.weight: copying a param with shape torch.Size([48, 25]) from checkpoint, the shape in current model is torch.Size([48, 14]).\n\tsize mismatch for transition_fxn.t_sigma.weight: copying a param with shape torch.Size([48, 73]) from checkpoint, the shape in current model is torch.Size([48, 62]).\n\tsize mismatch for prior_W.weight: copying a param with shape torch.Size([48, 41]) from checkpoint, the shape in current model is torch.Size([48, 30]).\n\tsize mismatch for prior_sigma.weight: copying a param with shape torch.Size([48, 41]) from checkpoint, the shape in current model is torch.Size([48, 30]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-da03aa18efad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFixedTrial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'bs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reg_all'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reg_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dim_stochastic'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_stochastic\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/ml2/software/anaconda3/envs/disease_prog/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1045\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SSM:\n\tsize mismatch for transition_fxn.t_mu.control_layer.weight: copying a param with shape torch.Size([48, 25]) from checkpoint, the shape in current model is torch.Size([48, 14]).\n\tsize mismatch for transition_fxn.t_mu.logcell.controlfxn.weight: copying a param with shape torch.Size([48, 24]) from checkpoint, the shape in current model is torch.Size([48, 13]).\n\tsize mismatch for transition_fxn.t_mu.treatment_exp.alpha_1_layer.weight: copying a param with shape torch.Size([48, 25]) from checkpoint, the shape in current model is torch.Size([48, 14]).\n\tsize mismatch for transition_fxn.t_sigma.weight: copying a param with shape torch.Size([48, 73]) from checkpoint, the shape in current model is torch.Size([48, 62]).\n\tsize mismatch for prior_W.weight: copying a param with shape torch.Size([48, 41]) from checkpoint, the shape in current model is torch.Size([48, 30]).\n\tsize mismatch for prior_sigma.weight: copying a param with shape torch.Size([48, 41]) from checkpoint, the shape in current model is torch.Size([48, 30])."
     ]
    }
   ],
   "source": [
    "mname = {}; models = {}; fold = 1\n",
    "mmdata = load_mmrf(fold_span = [fold], \\\n",
    "                              digitize_K = 20, \\\n",
    "                              digitize_method = 'uniform', \\\n",
    "                              suffix='_2mos', \\\n",
    "                              restrict_markers=[], \\\n",
    "                              add_syn_marker=False, \\\n",
    "                              window='all', \\\n",
    "                              data_aug=False)\n",
    "# mname[f'ssm-lin-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold3_ssm_lin_epoch=08465-val_loss=80.52.ckpt'\n",
    "# mname[f'ssm-att-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold3_ssm_att1epoch=13974-val_loss=53.37.ckpt'\n",
    "# mname[f'ssm-lin-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold1ssm_linepoch=14004-val_loss=74.14.ckpt'\n",
    "# mname[f'ssm-att-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold1_ssm_att1epoch=13696-val_loss=57.20.ckpt'\n",
    "mname[f'ssm-att-fold{fold}'] = '../ief_core/tests/checkpoints/baseline_ablation/mmfold164_attn_transition_iss_ssm_baseablationepoch=12986-val_loss=58.10.ckpt'\n",
    "# mname[f'ssm-att-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold1_regFalse_ssm_att1epoch=13142-val_loss=63.89.ckpt'\n",
    "## fold 0 \n",
    "if fold == 0: \n",
    "    mname[f'ssm-lin-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold0_ssm_lin_epoch=14605-val_loss=88.48.ckpt'\n",
    "    mname[f'ssm-nl-fold{fold}']  = '../ief_core/tests/checkpoints/mmfold0_ssm_nl_epoch=07451-val_loss=83.10.ckpt'\n",
    "    mname[f'ssm-moe-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold0_ssm_moe_epoch=10475-val_loss=74.12.ckpt'\n",
    "    mname[f'ssm-att-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold0_ssm_att1epoch=14148-val_loss=65.06.ckpt'\n",
    "    mname[f'ssm-att12-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold0_ssm_att1_att2epoch=14135-val_loss=64.56.ckpt'\n",
    "    mname[f'ssm-baseline{fold}'] = '../ief_core/tests/checkpoints/mmfold0ssm_baselineepoch=14285-val_loss=99.59.ckpt'\n",
    "elif fold == 1:\n",
    "# #     ## fold 1 \n",
    "    mname[f'ssm-lin-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold1ssm_linepoch=14004-val_loss=74.14.ckpt'\n",
    "#     mname[f'ssm-nl-fold{fold}']  = '../ief_core/tests/checkpoints/mmfold1_ssm_nl_epoch=07519-val_loss=76.88.ckpt'\n",
    "#     mname[f'ssm-moe-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold1_ssm_moe_epoch=12673-val_loss=71.12.ckpt'\n",
    "    mname[f'ssm-att-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold1_ssm_att1epoch=13696-val_loss=57.20.ckpt'\n",
    "#     mname[f'ssm-att12-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold1_ssm_att1_att2epoch=13623-val_loss=59.14.ckpt'\n",
    "#     mname[f'ssm-baseline{fold}'] = '../ief_core/tests/checkpoints/mmfold1ssm_baselineepoch=14997-val_loss=92.22.ckpt'\n",
    "elif fold == 2: \n",
    "#     ## fold 2\n",
    "    mname[f'ssm-lin-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold2_ssm_lin_epoch=10805-val_loss=91.49.ckpt'\n",
    "    mname[f'ssm-nl-fold{fold}']  = '../ief_core/tests/checkpoints/mmfold2_ssm_nl_epoch=07478-val_loss=84.18.ckpt'\n",
    "    mname[f'ssm-moe-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold2_ssm_moe_epoch=14598-val_loss=77.14.ckpt'\n",
    "    mname[f'ssm-att-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold2_ssm_att1epoch=14798-val_loss=66.73.ckpt'\n",
    "    mname[f'ssm-att12-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold2_ssm_att1_att2epoch=14606-val_loss=69.02.ckpt'\n",
    "    mname[f'ssm-baseline{fold}'] = '../ief_core/tests/checkpoints/mmfold2ssm_baselineepoch=12751-val_loss=97.99.ckpt'\n",
    "elif fold == 3:\n",
    "#     ## fold 3 \n",
    "    mname[f'ssm-lin-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold3_ssm_lin_epoch=08465-val_loss=80.52.ckpt'\n",
    "    mname[f'ssm-nl-fold{fold}']  = '../ief_core/tests/checkpoints/mmfold3_ssm_nl_epoch=08438-val_loss=70.79.ckpt'\n",
    "    mname[f'ssm-moe-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold3_ssm_moe_epoch=07993-val_loss=63.16.ckpt'\n",
    "    mname[f'ssm-att-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold3_ssm_att1epoch=13974-val_loss=53.37.ckpt'\n",
    "    mname[f'ssm-att12-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold3_ssm_att1_att2epoch=11925-val_loss=55.52.ckpt'\n",
    "    mname[f'ssm-baseline{fold}'] = '../ief_core/tests/checkpoints/mmfold3ssm_baselineepoch=13696-val_loss=88.13.ckpt'\n",
    "elif fold == 4: \n",
    "#     ## fold 4\n",
    "    mname[f'ssm-lin-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold4_ssm_lin_epoch=13385-val_loss=79.35.ckpt'\n",
    "    mname[f'ssm-nl-fold{fold}']  = '../ief_core/tests/checkpoints/mmfold4_ssm_nl_epoch=07690-val_loss=74.66.ckpt'\n",
    "    mname[f'ssm-moe-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold4_ssm_moe_epoch=08201-val_loss=66.47.ckpt'\n",
    "    mname[f'ssm-att-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold4_ssm_att1epoch=13337-val_loss=58.12.ckpt'\n",
    "    mname[f'ssm-att12-fold{fold}'] = '../ief_core/tests/checkpoints/mmfold4_ssm_att1_att2epoch=13966-val_loss=57.53.ckpt'\n",
    "    mname[f'ssm-baseline{fold}'] = '../ief_core/tests/checkpoints/mmfold4ssm_baselineepoch=08013-val_loss=94.48.ckpt'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device  = torch.device('cpu')\n",
    "print(mname.keys())\n",
    "for model_n in mname.keys(): \n",
    "    checkpoint = torch.load(mname[model_n], map_location=lambda storage, loc: storage)\n",
    "    hparams    = checkpoint['hyper_parameters']\n",
    "    if 'lin' in model_n: \n",
    "        hparams['include_baseline'] = 'all'\n",
    "        print(hparams['include_baseline'])\n",
    "    print(model_n)\n",
    "    print(hparams)\n",
    "    del hparams['trial']\n",
    "    if 'baseline' in model_n: \n",
    "        trial = optuna.trial.FixedTrial({'bs': hparams.bs, 'lr': hparams.lr, 'C': hparams.C, 'reg_all': hparams.reg_all, 'reg_type': hparams.reg_type, 'dim_stochastic': hparams.dim_stochastic})\n",
    "        model = SSMBaseline(trial, **hparams); model.setup(1)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        models[model_n] = model\n",
    "        models[model_n].to(device)\n",
    "    elif 'ssm' in model_n and 'att12' not in model_n: \n",
    "        trial = optuna.trial.FixedTrial({'bs': hparams.bs, 'lr': hparams.lr, 'C': hparams.C, 'reg_all': hparams.reg_all, 'reg_type': hparams.reg_type, 'dim_stochastic': hparams.dim_stochastic})\n",
    "        model = SSM(trial, **hparams); model.setup(1)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        models[model_n] = model\n",
    "        models[model_n].to(device)\n",
    "    elif 'ssm' in model_n and 'att12' in model_n: \n",
    "        trial = optuna.trial.FixedTrial({'bs': hparams.bs, 'lr': hparams.lr, 'C': hparams.C, 'reg_all': hparams.reg_all, 'reg_type': hparams.reg_type, 'dim_stochastic': hparams.dim_stochastic})\n",
    "        model = SSMAtt(trial, **hparams); model.setup(1)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        models[model_n] = model\n",
    "        models[model_n].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using digitized y\n",
      "ssm-att-fold1 vs ssm-lin-fold1: mean -- 0.7053418803418802, std -- 0.45505985131962723\n",
      "ssm-att-fold1 nelbo: 61.5250244140625\n",
      "ssm-lin-fold1 nelbo: 73.71952819824219\n",
      "{'ssm-lin-fold1': SSM(\n",
      "  (inf_network): RNN_STInf(\n",
      "    (inf_rnn): GRU(42, 300, batch_first=True, bidirectional=True)\n",
      "    (hid_rnn_zt): Linear(in_features=600, out_features=300, bias=True)\n",
      "    (base_h1): Linear(in_features=41, out_features=300, bias=True)\n",
      "    (hid_ztm1_zt): Linear(in_features=16, out_features=300, bias=True)\n",
      "    (mu_zt): Linear(in_features=300, out_features=16, bias=True)\n",
      "    (sigma_zt): Linear(in_features=300, out_features=16, bias=True)\n",
      "    (mu_zt2): Linear(in_features=300, out_features=16, bias=True)\n",
      "    (sigma_zt2): Linear(in_features=300, out_features=16, bias=True)\n",
      "  )\n",
      "  (e_mu): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (e_sigma): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (transition_fxn): TransitionFunction(\n",
      "    (t_mu): Linear(in_features=41, out_features=16, bias=True)\n",
      "    (t_sigma): Linear(in_features=41, out_features=16, bias=True)\n",
      "  )\n",
      "  (prior_W): Linear(in_features=41, out_features=16, bias=True)\n",
      "  (prior_sigma): Linear(in_features=41, out_features=16, bias=True)\n",
      "), 'ssm-att-fold1': SSM(\n",
      "  (inf_network): RNN_STInf(\n",
      "    (inf_rnn): GRU(42, 300, batch_first=True, bidirectional=True)\n",
      "    (hid_rnn_zt): Linear(in_features=600, out_features=300, bias=True)\n",
      "    (base_h1): Linear(in_features=41, out_features=300, bias=True)\n",
      "    (hid_ztm1_zt): Linear(in_features=48, out_features=300, bias=True)\n",
      "    (mu_zt): Linear(in_features=300, out_features=48, bias=True)\n",
      "    (sigma_zt): Linear(in_features=300, out_features=48, bias=True)\n",
      "    (mu_zt2): Linear(in_features=300, out_features=48, bias=True)\n",
      "    (sigma_zt2): Linear(in_features=300, out_features=48, bias=True)\n",
      "  )\n",
      "  (e_mu): Linear(in_features=48, out_features=16, bias=True)\n",
      "  (e_sigma): Linear(in_features=48, out_features=16, bias=True)\n",
      "  (transition_fxn): TransitionFunction(\n",
      "    (t_mu): AttentionIEFTransition(\n",
      "      (out_layer): Linear(in_features=48, out_features=48, bias=True)\n",
      "      (control_layer): Linear(in_features=25, out_features=48, bias=True)\n",
      "      (inp_layer): Linear(in_features=48, out_features=48, bias=True)\n",
      "      (attn): MultiHeadedAttention(\n",
      "        (linears): ModuleList(\n",
      "          (0): Linear(in_features=48, out_features=48, bias=True)\n",
      "          (1): Linear(in_features=48, out_features=48, bias=True)\n",
      "          (2): Linear(in_features=48, out_features=48, bias=True)\n",
      "          (3): Linear(in_features=48, out_features=48, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (logcell): LogCellKill(\n",
      "        (controlfxn): Linear(in_features=24, out_features=48, bias=True)\n",
      "      )\n",
      "      (treatment_exp): TreatmentExponential(\n",
      "        (pred_prms): Linear(in_features=3, out_features=3, bias=True)\n",
      "        (alpha_1_layer): Linear(in_features=25, out_features=48, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (t_sigma): Linear(in_features=73, out_features=48, bias=True)\n",
      "  )\n",
      "  (prior_W): Linear(in_features=41, out_features=48, bias=True)\n",
      "  (prior_sigma): Linear(in_features=41, out_features=48, bias=True)\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "data, data_loader   = models[f'ssm-att-fold{fold}'].load_helper('test', device=device, att_mask=True)\n",
    "(B, X, A, M, Y, CE, Am) = data_loader.dataset.tensors\n",
    "_, _, lens = get_masks(M)\n",
    "B, X, A, M, Y, CE, Am  = B[lens>1], X[lens>1], A[lens>1], M[lens>1], Y[lens>1], CE[lens>1], Am[lens>1]\n",
    "\n",
    "nelbos = {}\n",
    "\n",
    "# prepare list of things to compare (i.e. lotc)\n",
    "# lotc = [(f'ssm-att-fold{fold}', f'ssm-lin-fold{fold}'),(f'ssm-att-fold{fold}', f'ssm-nl-fold{fold}'),(f'ssm-att-fold{fold}', f'ssm-moe-fold{fold}')]\n",
    "# lotc = [(f'ssm-att-fold{fold}', f'ssm-baseline{fold}')]\n",
    "lotc = [(f'ssm-att-fold{fold}', f'ssm-lin-fold{fold}')]\n",
    "\n",
    "for elem in lotc: \n",
    "    trials1 = []; trials2 = []\n",
    "    nelboP = []; nelboB = []\n",
    "    for t in range(20): \n",
    "        pkpd_n, base_n = elem\n",
    "        nelbo_pkpd, _, _, _ = models[pkpd_n].get_loss(B, X, A, M, Y, CE, anneal=1.)\n",
    "#         nelbo_base, _, _, _ = models[base_n].get_loss(B, X, A, M, Y, CE, Am, anneal=1.)\n",
    "        nelbo_base, _, _, _ = models[base_n].get_loss(B, X, A, M, Y, CE, anneal=1.)\n",
    "        is_pkpd_better = (nelbo_base - nelbo_pkpd) > 0.\n",
    "        trials1.append(np.mean(pt_numpy(is_pkpd_better))) \n",
    "        trials2.append(np.std(pt_numpy(is_pkpd_better)))\n",
    "        nelboP.append(np.mean(pt_numpy(nelbo_pkpd)))\n",
    "        nelboB.append(np.mean(pt_numpy(nelbo_base)))\n",
    "    print(f'{pkpd_n} vs {base_n}: mean -- {np.mean(trials1)}, std -- {np.mean(trials2)}')\n",
    "    print(f'{pkpd_n} nelbo: {np.mean(nelboP)}')\n",
    "    print(f'{base_n} nelbo: {np.mean(nelboB)}')\n",
    "\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_loader   = models[f'ssm-att-fold{fold}'].load_helper('test', device=device, att_mask=True)\n",
    "(B, X, A, M, Y, CE, Am) = data_loader.dataset.tensors\n",
    "_, _, lens = get_masks(M)\n",
    "B, X, A, M, Y, CE, Am  = B[lens>1], X[lens>1], A[lens>1], M[lens>1], Y[lens>1], CE[lens>1], Am[lens>1]\n",
    "\n",
    "nlls = {}\n",
    "\n",
    "lotc = [(f'ssm-att-fold{fold}', f'ssm-lin-fold{fold}'),(f'ssm-att-fold{fold}', f'ssm-nl-fold{fold}'),(f'ssm-att-fold{fold}', f'ssm-moe-fold{fold}'), (f'ssm-att-fold{fold}', f'ssm-baseline{fold}')]\n",
    "# lotc = [(f'ssm-att-fold{fold}', f'ssm-lin-fold{fold}')]\n",
    "\n",
    "for comp in lotc: \n",
    "    att = comp[0]\n",
    "    base = comp[1]\n",
    "#     print(f'MODEL COMP {att} vs ')\n",
    "    for model in [base, att]: \n",
    "        loss = models[model].imp_sampling(B, X, A, M, Y, CE, imp_samples = 25, idx = -1)\n",
    "        mloss = pt_numpy(loss[0])\n",
    "        nlls[model] = mloss\n",
    "\n",
    "    thres = 10\n",
    "    print(f'total examples: {len(nlls[att])}')\n",
    "    num_pk_better  = np.sum(nlls[base] > (nlls[att] + thres))\n",
    "    print(f'num examples where {att} does better: {num_pk_better}, {num_pk_better / len(nlls[att])}')\n",
    "    num_lin_better = np.sum(nlls[att] > (nlls[base] + thres))\n",
    "    print(f'num examples where {base} does better: {num_lin_better}, {num_lin_better / len(nlls[att])}')\n",
    "    t1 = np.sum((nlls[base] > (nlls[att] - thres)) & (nlls[base] < (nlls[att] + thres)))\n",
    "    print(f'num examples where it is unclear: {t1}, {t1 / len(nlls[att])}')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights on $\\alpha_1$ Linear Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['iss', 'age', 'gender', 'ecog', 'serum_beta2_microglobulin', 'PC1',\n",
      "       'PC2', 'PC3', 'PC4', 'PC5', 'heavy_chain', 'igg_type', 'iga_type',\n",
      "       'igm_type', 'kappa_type', 'lambda_type'],\n",
      "      dtype='object')\n",
      "(41,) (16,)\n",
      "['cbc abs neut', 'chem albumin', 'chem bun', 'chem calcium', 'chem creatinine', 'chem glucose', 'cbc hemoglobin', 'serum kappa', 'serum m protein', 'cbc platelet', 'chem totprot', 'cbc wbc', 'serum iga', 'serum igg', 'serum igm', 'serum lambda']\n",
      "['local_clock' 'Bor' 'Car' 'Cyc' 'Dex' 'Len' 'line1' 'line2' 'line3plus']\n",
      "['cbc_abs_neut' 'chem_albumin' 'chem_bun' 'chem_calcium' 'chem_creatinine'\n",
      " 'chem_glucose' 'cbc_hemoglobin' 'serum_kappa' 'serum_m_protein'\n",
      " 'cbc_platelet' 'chem_totprot' 'cbc_wbc' 'serum_iga' 'serum_igg'\n",
      " 'serum_igm' 'serum_lambda' 'local_clock' 'Bor' 'Car' 'Cyc' 'Dex' 'Len'\n",
      " 'line1' 'line2' 'line3plus' 'iss' 'age' 'gender' 'ecog'\n",
      " 'serum_beta2_microglobulin' 'PC1' 'PC2' 'PC3' 'PC4' 'PC5' 'heavy_chain'\n",
      " 'igg_type' 'iga_type' 'igm_type' 'kappa_type' 'lambda_type']\n"
     ]
    }
   ],
   "source": [
    "X_names_orig = mmdata[fold]['train']['feature_names_x']\n",
    "X_names = mmdata[fold]['train']['feature_names_x']\n",
    "A_names = mmdata[fold]['train']['feature_names_a']\n",
    "B_names = mmdata[fold]['train']['feature_names']\n",
    "all_names = np.concatenate([X_names, A_names, B_names],0)\n",
    "print(B_names)\n",
    "print (all_names.shape, X_names.shape)\n",
    "X_names = [s.replace('_', ' ') for s in X_names]\n",
    "print(X_names)\n",
    "print(A_names)\n",
    "print(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from pyro.distributions import Normal, Independent, Categorical, LogNormal\n",
    "\n",
    "class ModelIntrospector: \n",
    "    def __init__(self, model, data_loader, feat_names):\n",
    "        self.model       = model \n",
    "        self.data_loader = data_loader\n",
    "        self.X_names, self.A_names, self.B_names = feat_names\n",
    "\n",
    "    def _stratify(self, stratify_params=None): \n",
    "        (B, X, A, M, Y, CE) = self.data_loader.dataset.tensors \n",
    "        if not stratify_params: \n",
    "            return (B, X, A, M, Y, CE)\n",
    "        feat, val, keep_censored = stratify_params['feat'], stratify_params['val'], stratify_params['keep_censored']\n",
    "        idx = np.where(self.B_names == feat)[0]\n",
    "        if not keep_censored: \n",
    "            B = B[np.where(CEn==1)[0]]\n",
    "            X = X[np.where(CEn==1)[0]]\n",
    "            A = A[np.where(CEn==1)[0]]\n",
    "            M = M[np.where(CEn==1)[0]]\n",
    "            Y = Y[np.where(CEn==1)[0]]\n",
    "            CE = CE[np.where(CEn==1)[0]]\n",
    "        Bn  = pt_numpy(B)\n",
    "        pt_idxs = np.where(Bn[:,idx] == val)[0]\n",
    "        B, X, A, M, Y, CE   = B[pt_idxs], X[pt_idxs], A[pt_idxs], M[pt_idxs], Y[pt_idxs], CE[pt_idxs]\n",
    "        return (B, X, A, M, Y, CE)\n",
    "\n",
    "    def _get_con_signal(self, B, X, A, M, Y, CE, Tmax=None): \n",
    "        base_cat   = B[:,None,:].repeat(1, max(1, X.shape[1]-1), 1)\n",
    "        _, _, lens = get_masks(M)\n",
    "        B, X, A, M, Y, CE  = B[lens>1], X[lens>1], A[lens>1], M[lens>1], Y[lens>1], CE[lens>1]\n",
    "        X0 = X[:,0,:]; A0  = A[:,0,:]\n",
    "\n",
    "        # get alpha_1 \n",
    "        if Tmax == None: \n",
    "            Tmax = X.shape[1]-1\n",
    "        Aval = A[:,1:Tmax,:]\n",
    "        con  = torch.cat([Aval[...,[0]],B[:,None,:].repeat(1,Aval.shape[1],1), Aval[...,1:]],-1)\n",
    "        return con\n",
    "\n",
    "    def _p_Zt(self, B, X, A, M, Y, CE, dist='posterior'): \n",
    "        base_cat   = B[:,None,:].repeat(1, max(1, X.shape[1]-1), 1)\n",
    "        _, _, lens = get_masks(M)\n",
    "        B, X, A, M, Y, CE  = B[lens>1], X[lens>1], A[lens>1], M[lens>1], Y[lens>1], CE[lens>1]\n",
    "        X0 = X[:,0,:]; A0  = A[:,0,:]\n",
    "\n",
    "        if dist == 'posterior': \n",
    "            Z_t, q_zt = self.model.inf_network(X, A, M, B)\n",
    "        elif dist == 'prior': \n",
    "            Tmax     = X.shape[1]-1\n",
    "            inp_cat  = torch.cat([B, X0, A0], -1)\n",
    "            mu1      = self.model.prior_W(inp_cat)\n",
    "            sig1     = torch.nn.functional.softplus(self.model.prior_sigma(inp_cat))\n",
    "            Z_start  = torch.squeeze(Independent(Normal(mu1, sig1), 1).sample((1,)))\n",
    "            meanlist = [mu1[:,None,:]]\n",
    "            sigmalist= [sig1[:,None,:]]\n",
    "            Zlist    = [Z_start]\n",
    "            for t in range(1, Tmax):\n",
    "                Ztm1       = Zlist[t-1]\n",
    "                if self.model.hparams.include_baseline:\n",
    "                    Aval = A[:,t-1,:]\n",
    "                    Acat = torch.cat([Aval[...,[0]], B, Aval[...,1:]], -1)\n",
    "                    mut, sigmat= self.model.transition_fxn(Ztm1, Acat)\n",
    "                else:\n",
    "                    mut, sigmat= self.transition_fxn(Ztm1, A[:,t-1,:])\n",
    "                meanlist.append(mut[:,None,:])\n",
    "                sigmalist.append(sigmat[:,None,:])\n",
    "                Zlist.append(torch.squeeze(Independent(Normal(mut, sigmat), 1).sample((1,))))\n",
    "            mu_prior, std_prior = torch.cat(meanlist, 1), torch.cat(sigmalist, 1)\n",
    "            Z_t  = torch.cat([k[:,None,:] for k in Zlist],1)\n",
    "        else: \n",
    "            raise ValueError('bad distribution type...')\n",
    "\n",
    "        return Z_t[:,:-1,:]\n",
    "\n",
    "    def get_ensemble_weights(self): \n",
    "        return torch.softmax(self.model.transition_fxn.t_mu.alphas, 1)\n",
    "\n",
    "    def get_te_alpha1(self): \n",
    "        str_tensors = self._stratify()\n",
    "        con = self._get_con_signal(*str_tensors)\n",
    "        return self.model.transition_fxn.t_mu.treatment_exp.alpha_1_layer(con)\n",
    "\n",
    "    def get_te_alpha1_weights(self): \n",
    "        return self.model.transition_fxn.t_mu.treatment_exp.alpha_1_layer.weight\n",
    "\n",
    "    def jacobian_alpha1(self, stratify_params=None): \n",
    "        We = self.model.e_mu.weight \n",
    "        Wo = self.model.transition_fxn.t_mu.out_layer.weight \n",
    "        te_weight = self.get_ensemble_weights()[:,2]\n",
    "\n",
    "        print('Emission weights shape....', We.shape)\n",
    "        print('Output layer weights shape...', Wo.shape)\n",
    "        print('Ensemble treatment effect function weights...', te_weight.shape)\n",
    "\n",
    "        # compute jacobian\n",
    "        str_tensors = self._stratify(stratify_params)\n",
    "        con = self._get_con_signal(*str_tensors, Tmax=None)\n",
    "        tvals = con[...,[0]]\n",
    "        tmax_lot = ((tvals*con[...,-3:]).max(1, keepdims=True)[0]*con[...,-3:]).sum(-1, keepdims=True)\n",
    "        pred     = self.model.transition_fxn.t_mu.treatment_exp.pred_prms(con[...,-3:])\n",
    "        alpha_2, alpha_3, gamma = torch.sigmoid(pred[...,[0]]), torch.sigmoid(pred[...,[1]]), torch.sigmoid(pred[...,[2]])*tmax_lot\n",
    "        mask     = (tvals-gamma)\n",
    "        mask[mask<=0]= 0\n",
    "        mask[mask>0] = 1\n",
    "        res1 = (1-mask)*(1/(1+torch.exp(-alpha_2*(tvals-0.5*gamma))))\n",
    "        res2 = mask*(1/((1+torch.exp(-alpha_3*0.5*gamma))*(1+torch.exp(alpha_3*(tvals-1.5*gamma)))))\n",
    "        res  = res1+res2\n",
    "        J    = torch.matmul(torch.matmul(res*te_weight[None,None,:], Wo.T), We.T) # should i have transposed?? \n",
    "        print('Jacobian shape...', (J.shape))\n",
    "\n",
    "        return J \n",
    "\n",
    "    def jacobian_trt(self, trt, expect='posterior', stratify_params=None): \n",
    "        We = self.model.e_mu.weight \n",
    "        Wo = self.model.transition_fxn.t_mu.out_layer.weight \n",
    "        te_weight1 = self.get_ensemble_weights()[:,0]\n",
    "        te_weight2 = self.get_ensemble_weights()[:,1]\n",
    "        te_weight3 = self.get_ensemble_weights()[:,2]\n",
    "\n",
    "        str_tensors = self._stratify(stratify_params)\n",
    "        inpx = self._p_Zt(*str_tensors, expect)\n",
    "        con  = self._get_con_signal(*str_tensors, Tmax=inpx.shape[1]+1)\n",
    "\n",
    "        # term 1\n",
    "        i1   = inpx*(1 - torch.tanh(self.model.transition_fxn.t_mu.control_layer(con))**2)\n",
    "        Wlin = self.model.transition_fxn.t_mu.control_layer.weight[:,-(trt.shape[-1]):]\n",
    "        t1   = torch.matmul(We, torch.matmul(Wo, torch.matmul(torch.diag_embed(i1*te_weight1[None,None,:]), Wlin)))\n",
    "\n",
    "        # term 2 \n",
    "        a    = con[...,1:]\n",
    "        i2   = inpx*(1 - torch.tanh(self.model.transition_fxn.t_mu.logcell.controlfxn(a)))\n",
    "        Wlc  = self.model.transition_fxn.t_mu.logcell.controlfxn.weight[:,-(trt.shape[-1]):]\n",
    "        t2   = torch.matmul(We, torch.matmul(Wo, torch.matmul(torch.diag_embed(i2*te_weight2[None,None,:]), Wlc)))\n",
    "\n",
    "        # term 3\n",
    "        tvals = con[...,[0]]\n",
    "        tmax_lot = ((tvals*con[...,-3:]).max(1, keepdims=True)[0]*con[...,-3:]).sum(-1, keepdims=True)\n",
    "        pred     = self.model.transition_fxn.t_mu.treatment_exp.pred_prms(con[...,-3:])\n",
    "        alpha_2, alpha_3, gamma = torch.sigmoid(pred[...,[0]]), torch.sigmoid(pred[...,[1]]), torch.sigmoid(pred[...,[2]])*tmax_lot\n",
    "        mask     = (tvals-gamma)\n",
    "        mask[mask<=0]= 0\n",
    "        mask[mask>0] = 1\n",
    "        res1 = (1-mask)*(1/(1+torch.exp(-alpha_2*(tvals-0.5*gamma))))\n",
    "        res2 = mask*(1/((1+torch.exp(-alpha_3*0.5*gamma))*(1+torch.exp(alpha_3*(tvals-1.5*gamma)))))\n",
    "        i3   = res1+res2\n",
    "        Wte  = self.model.transition_fxn.t_mu.treatment_exp.alpha_1_layer.weight[...,-(trt.shape[-1]):]\n",
    "        t3   = torch.matmul(We,torch.matmul(Wo,torch.matmul(torch.diag_embed(i3*te_weight3[None,None,:]), Wte)))\n",
    "\n",
    "        # result (compute directional derivative)\n",
    "        grad  = t1 + t2 + t3 \n",
    "        return torch.matmul(grad, trt)\n",
    "\n",
    "    def get_alpha1_tsne(self, bins, time=None, verbose=True): \n",
    "        alpha_1 = self.get_te_alpha1() \n",
    "        (B, X, A, M, Y, CE) = self.data_loader.dataset.tensors\n",
    "        _, _, lens = get_masks(M)\n",
    "        B, X, A, M, Y, CE  = B[lens>1], X[lens>1], A[lens>1], M[lens>1], Y[lens>1], CE[lens>1]\n",
    "\n",
    "        Yn = pt_numpy(Y); CEn = pt_numpy(CE)\n",
    "        Yn_obs     = Yn[np.where(CEn==1)[0]]\n",
    "        Yidx_obs   = np.where(Yn_obs==1)[1]\n",
    "        binY       = np.digitize(Yidx_obs, bins)\n",
    "\n",
    "        # print out information \n",
    "        if verbose: \n",
    "            print(f'time of death (observed+censored): {np.where(Yn==1)[1]}, {len(np.where(Yn==1)[0])}')\n",
    "            print(f'time of death (observed): {Yidx_obs}, {len(Yidx_obs)}')\n",
    "            print(f'binned Y: {binY}')\n",
    "        ys = []\n",
    "        for i in range(len(bins)): \n",
    "            y = np.where(binY == i)[0]\n",
    "            ys.append(y)\n",
    "            if verbose: \n",
    "                print(f'number of patients in group y{i+1}: {y.shape[0]}')\n",
    "\n",
    "        result_CEs = []\n",
    "        weights = models[f'ssm-att-fold{fold}'].transition_fxn.t_mu.attn.attn.squeeze()\n",
    "        # run TSNEs for all t if no time range specified\n",
    "        if time is None: \n",
    "            time = np.arange(alpha_1.shape[1])\n",
    "        for t in time: \n",
    "            tsne = TSNE(n_components = 2)\n",
    "#             idxs = np.where(np.mean(pt_numpy(weights[:,t,:]),dim=0)>0.7)[0]\n",
    "            idxs = np.where(np.mean(pt_numpy(weights[:,t,:,-1]),axis=0)>0.5)[0]\n",
    "            result = tsne.fit_transform(pt_numpy(alpha_1[:,t,idxs]))\n",
    "            result_CE = result[np.where(CEn==1)[0]]\n",
    "            result_CEs.append(result_CE)\n",
    "        \n",
    "        return result_CEs, ys\n",
    "    \n",
    "    def get_latent_tsne(self, bins, time=None, verbose=True): \n",
    "        (B, X, A, M, Y, CE) = self.data_loader.dataset.tensors\n",
    "        _, _, lens = get_masks(M)\n",
    "        B, X, A, M, Y, CE  = B[lens>1], X[lens>1], A[lens>1], M[lens>1], Y[lens>1], CE[lens>1]\n",
    "        Zt = self._p_Zt(B, X, A, M, Y, CE, dist='posterior')\n",
    "        \n",
    "        Yn = pt_numpy(Y); CEn = pt_numpy(CE)\n",
    "        Yn_obs     = Yn[np.where(CEn==1)[0]]\n",
    "        Yidx_obs   = np.where(Yn_obs==1)[1]\n",
    "        binY       = np.digitize(Yidx_obs, bins)\n",
    "\n",
    "        # print out information \n",
    "        if verbose: \n",
    "            print(f'time of death (observed+censored): {np.where(Yn==1)[1]}, {len(np.where(Yn==1)[0])}')\n",
    "            print(f'time of death (observed): {Yidx_obs}, {len(Yidx_obs)}')\n",
    "            print(f'binned Y: {binY}')\n",
    "        ys = []\n",
    "        for i in range(len(bins)): \n",
    "            y = np.where(binY == i)[0]\n",
    "            ys.append(y)\n",
    "            if verbose: \n",
    "                print(f'number of patients in group y{i+1}: {y.shape[0]}')\n",
    "\n",
    "        result_CEs = []\n",
    "        # run TSNEs for all t if no time range specified\n",
    "        if time is None: \n",
    "            time = np.arange(alpha_1.shape[1])\n",
    "        for t in time: \n",
    "            tsne = TSNE(n_components = 2)\n",
    "            result = tsne.fit_transform(pt_numpy(Zt[:,t,:]))\n",
    "            result_CE = result[np.where(CEn==1)[0]]\n",
    "            result_CEs.append(result_CE)\n",
    "        \n",
    "        return result_CEs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_loader   = models[f'ssm-att-fold{fold}'].load_helper('test', device=device)\n",
    "EI = ModelIntrospector(models[f'ssm-att-fold{fold}'], data_loader, [X_names, A_names, B_names])\n",
    "alpha_weights = EI.get_te_alpha1_weights()[:,-8:]\n",
    "Anames_trt = A_names[1:]\n",
    "fig, ax = plt.subplots(figsize=(15,11))\n",
    "sns.heatmap(pt_numpy(alpha_weights), ax=ax, cmap='Blues', xticklabels=Anames_trt, yticklabels=False)\n",
    "ax.set_ylabel('alpha-1 (dim=48)', fontsize=40)\n",
    "ax.tick_params(axis='x', labelsize=40)\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(55)\n",
    "cbar = ax.collections[0].colorbar\n",
    "# here set the labelsize by 20\n",
    "cbar.ax.tick_params(labelsize=35)\n",
    "plt.savefig('./plots/aaai-plots/ssm_alpha1_matrix.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_loader   = models[f'ssm-att-fold{fold}'].load_helper('test', device=device)\n",
    "(B, X, A, M, Y, CE) = data_loader.dataset.tensors\n",
    "_, _, lens         = get_masks(M)\n",
    "B, X, A, M, Y, CE  = B[lens>1], X[lens>1], A[lens>1], M[lens>1], Y[lens>1], CE[lens>1]\n",
    "m_t, m_g_t, _      = get_masks(M[:,1:,:])\n",
    "Zt, q_zt          = models[f'ssm-att-fold{fold}'].inf_network(X, A, M, B)\n",
    "Tmax               = Zt.shape[1]\n",
    "X0 = X[:,0,:]; Xt = X[:,1:,:]\n",
    "inp_cat  = torch.cat([B, X0, A[:,0,:]], -1)\n",
    "# mu1      = self.prior_W(inp_cat)[:,None,:]\n",
    "# sig1     = torch.nn.functional.softplus(self.prior_sigma(inp_cat))[:,None,:]\n",
    "Zinp = Zt[:,:-1,:]; Aval = A[:,1:Tmax,:]\n",
    "Acat = torch.cat([Aval[...,[0]],B[:,None,:].repeat(1,Aval.shape[1],1), Aval[...,1:]],-1)\n",
    "inpx = Zinp; con = Acat\n",
    "t_mu = models[f'ssm-att-fold{fold}'].transition_fxn.t_mu\n",
    "#             mu2T, sig2T = self.transition_fxn(Zinp, Acat, eps = eps)\n",
    "inp        = t_mu.inp_layer(inpx)\n",
    "out_linear = inp*torch.tanh(t_mu.control_layer(con))\n",
    "out_te     = t_mu.treatment_exp(inp, con)\n",
    "out_logcell= t_mu.logcell(inp, con)\n",
    "value = torch.cat((out_linear[...,None], out_te[...,None], out_logcell[...,None]), dim=-1).transpose(-2,-1)\n",
    "key   = torch.cat((out_linear[...,None], out_te[...,None], out_logcell[...,None]), dim=-1).transpose(-2,-1)\n",
    "query = inp[...,None,:]\n",
    "t_mu.attn.dropout = None\n",
    "_     = t_mu.attn(query, key, value, use_matmul=False)\n",
    "#         out   = self.attn.forward(query, key, value, use_matmul=False).squeeze()\n",
    "# p_x_mu, p_x_std    = self.p_X_Z(Z_t, A[:,1:Tmax+1,[0]])\n",
    "# p_zt               = self.p_Zt_Ztm1(Z_t, A, B, X, A[:,0,:])\n",
    "# print(models[f'ssm-att-fold{fold}'].transition_fxn.t_mu.attn.attn.squeeze()[10:12].shape)\n",
    "print(models[f'ssm-att-fold{fold}'].transition_fxn.t_mu.attn.attn.squeeze()[:2].shape)\n",
    "print(torch.mean(models[f'ssm-att-fold{fold}'].transition_fxn.t_mu.attn.attn.squeeze()[:2],dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models[f'ssm-att-fold{fold}'].transition_fxn.t_mu.attn.attn.squeeze().shape)\n",
    "print(B_names)\n",
    "\n",
    "temp1 = models[f'ssm-att-fold{fold}'].transition_fxn.t_mu.attn.attn.squeeze()\n",
    "temp2 = models[f'ssm-att-fold{fold}'].transition_fxn.t_mu.attn.attn.squeeze()\n",
    "\n",
    "weights  = torch.mean(torch.mean(temp1,dim=0)[:3],dim=0)\n",
    "# weights  = torch.mean(models[f'ssm-att-fold{fold}'].transition_fxn.t_mu.attn.attn.squeeze()[19],dim=0)\n",
    "fig_dims = (8,10)\n",
    "fig, ax  = plt.subplots(figsize=fig_dims)\n",
    "print(pt_numpy(weights).shape)\n",
    "ax.tick_params(labelsize=30)\n",
    "ax2 = sns.heatmap(pt_numpy(weights), cmap=\"Greens\", yticklabels=False, xticklabels=['$g_1$', '$g_2$', '$g_3$'], ax=ax)\n",
    "# use matplotlib.colorbar.Colorbar object\n",
    "cbar = ax2.collections[0].colorbar\n",
    "# here set the labelsize by 20\n",
    "cbar.ax.tick_params(labelsize=22)\n",
    "plt.ylabel('State Space Dimension', fontsize=30)\n",
    "plt.savefig('./plots/aaai-plots/ssm_pkpd_attmap_first10months.pdf',bbox_inches='tight')\n",
    "\n",
    "# three-dimensional state; each dimension is a\n",
    "print(np.unique(np.where(pt_numpy(M[:,29:30,:]))[0]))\n",
    "weights  = torch.mean(torch.mean(temp2[np.unique(np.where(pt_numpy(M[:,22:24,:]))[0])],dim=0)[22:24],dim=0)\n",
    "fig_dims = (8,10)\n",
    "fig, ax  = plt.subplots(figsize=fig_dims)\n",
    "ax.tick_params(labelsize=30)\n",
    "ax2 = sns.heatmap(pt_numpy(weights), cmap=\"Greens\", yticklabels=False, xticklabels=['$g_1$', '$g_2$', '$g_3$'], ax=ax)\n",
    "# use matplotlib.colorbar.Colorbar object\n",
    "cbar = ax2.collections[0].colorbar\n",
    "# here set the labelsize by 20\n",
    "cbar.ax.tick_params(labelsize=22)\n",
    "plt.ylabel('State Space Dimension', fontsize=30)\n",
    "plt.savefig('./plots/ssm_pkpd_attmap_last10months_nonmissing.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLL Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names = mmdata[fold]['train']['feature_names_x']\n",
    "A_names = mmdata[fold]['train']['feature_names_a']\n",
    "B_names = mmdata[fold]['train']['feature_names']\n",
    "all_names = np.concatenate([X_names, A_names, B_names],0)\n",
    "print (all_names.shape, X_names.shape)\n",
    "X_names = [s.replace('_', ' ') for s in X_names]\n",
    "print(X_names)\n",
    "print(A_names)\n",
    "print(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify_by_nll(B, X, A, M, Y, CE, thr=20.):\n",
    "    thr = 20.\n",
    "    model_loss = {}\n",
    "    for model in models: \n",
    "        loss = models[model].get_loss(B, X, A, M, Y, CE)\n",
    "        mloss = pt_numpy(loss[0])\n",
    "        print(model)\n",
    "        model_loss[model] = mloss \n",
    "    lin_loss = model_loss[f'ssm-lin-fold{fold}']; gated_loss = model_loss[f'ssm-att-fold{fold}']\n",
    "    diff = (lin_loss - gated_loss)\n",
    "    idxlist = np.where(diff >= thr)[0]\n",
    "    # gated_sub = gated_loss[idxlist]\n",
    "\n",
    "    return B[idxlist], X[idxlist], A[idxlist], M[idxlist], Y[idxlist], CE[idxlist]\n",
    "\n",
    "def stratify_by_lens(B, X, A, M, Y, CE, slen=20): \n",
    "    _, _, lens = get_masks(M)\n",
    "    return B[lens>slen], X[lens>slen], A[lens>slen], M[lens>slen], Y[lens>slen], CE[lens>slen]\n",
    "\n",
    "def stratify_by_line(B, X, A, M, Y, CE): \n",
    "    # filter out patients who don't have second or third line therapies \n",
    "    idxs = np.unique(np.where(pt_numpy(A)[...,-2:] == 1.)[0])\n",
    "    return B[idxs], X[idxs], A[idxs], M[idxs], Y[idxs], CE[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_loader = models[f'ssm-att-fold{fold}'].load_helper('test', device=device)\n",
    "(B, X, A, M, Y, CE) = data_loader.dataset.tensors\n",
    "print(B.shape)\n",
    "# look at examples that PK-PD models well \n",
    "# B, X, A, M, Y, CE = stratify_by_lens(B, X, A, M, Y, CE, slen=1)\n",
    "T_forward  = 10; T_condition = 10\n",
    "B, X, A, M, Y, CE = stratify_by_lens(B, X, A, M, Y, CE, slen=T_forward+T_condition)\n",
    "# B, X, A, M, Y, CE = stratify_by_line(B, X, A, M, Y, CE)\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['NLL (imp. sampling estimate)', 'Biomarker', 'model']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for idx, feat in enumerate(X_names):\n",
    "    nlls = {}\n",
    "    for model in [f'ssm-lin-fold{fold}', f'ssm-att-fold{fold}']: \n",
    "        loss = models[model].imp_sampling(B, X, A, M, Y, CE, imp_samples = 10, idx = idx)\n",
    "        mloss = pt_numpy(loss[0])\n",
    "        nlls[model] = mloss\n",
    "    \n",
    "    for i in range(len(nlls[f'ssm-att-fold{fold}'])): \n",
    "        df.loc[0 if pd.isnull(df.index.max()) else df.index.max() + 1] = [nlls[f'ssm-att-fold{fold}'][i], \" \".join([f for f in feat.split(\"_\")]), f'SSM PK-PD']\n",
    "        df.loc[0 if pd.isnull(df.index.max()) else df.index.max() + 1] = [nlls[f'ssm-lin-fold{fold}'][i], \" \".join([f for f in feat.split(\"_\")]), f'SSM Linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "a1 = sns.boxplot(ax=ax, x='Biomarker', y='NLL (imp. sampling estimate)', hue='model',\n",
    "            data=df, palette='muted', showfliers=False)\n",
    "# a1.set_ylim(-10,10)\n",
    "a1.set_ylabel('NLL (imp. sampling estimate)', fontsize=35)\n",
    "a1.set_xlabel('Biomarker', fontsize=35)\n",
    "a1.tick_params(axis='x', labelsize=28)\n",
    "a1.tick_params(axis='y', labelsize=28)\n",
    "a1.legend(fontsize=30)\n",
    "for item in a1.get_xticklabels():\n",
    "    item.set_rotation(55)\n",
    "fig.savefig('./plots/supp_fig2_bplot_nll_is.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Error Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize conditional samples (what happens if you condition on some amount of time)\n",
    "## try condition on 6 months, one year, two years \n",
    "pf_samples   = {}\n",
    "cond_samples = {}\n",
    "prior_samples= {}\n",
    "print(B.shape)\n",
    "T_condition  = 12; T_forward = 6\n",
    "nelbo, pf_nelbo, p_z_mu, q_z_mu, inp_x_post, inp_x = models[f'ssm-att-fold{fold}'].inspect(T_forward, T_condition, B, X, A, M, Y, CE, nsamples=5)\n",
    "_, pf_samples[f'ssm-att-fold{fold}'], _, _, cond_samples[f'ssm-att-fold{fold}'], prior_samples[f'ssm-att-fold{fold}'] = tuple([pt_numpy(k) for k in (nelbo, pf_nelbo, p_z_mu, q_z_mu, inp_x_post, inp_x)])\n",
    "nelbo, pf_nelbo, p_z_mu, q_z_mu, inp_x_post, inp_x = models[f'ssm-lin-fold{fold}'].inspect(T_forward, T_condition, B, X, A, M, Y, CE, nsamples=5)\n",
    "_, pf_samples[f'ssm-lin-fold{fold}'], _, _, cond_samples[f'ssm-lin-fold{fold}'], prior_samples[f'ssm-lin-fold{fold}'] = tuple([pt_numpy(k) for k in (nelbo, pf_nelbo, p_z_mu, q_z_mu, inp_x_post, inp_x)]) \n",
    "\n",
    "data_cond= pt_numpy(X[:,:T_condition+T_forward,:])\n",
    "obs_cond = pt_numpy(M[:,:T_condition+T_forward,:])\n",
    "a_cond   = pt_numpy(A[:,:T_condition+T_forward,:])\n",
    "# data_cond[obs_cond==0] = np.nan\n",
    "\n",
    "data_prior= pt_numpy(X[:,:T_forward,:])\n",
    "obs_prior = pt_numpy(M[:,:T_forward,:])\n",
    "a_prior   = pt_numpy(A[:,:T_forward,:])\n",
    "print(data_prior[:,0,:].shape)\n",
    "print(prior_samples[f'ssm-att-fold{fold}'][:,0,:].shape)\n",
    "assert data_prior[:,0,:].shape == prior_samples[f'ssm-att-fold{fold}'][:,0,:].shape\n",
    "# data_prior[obs_prior==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['MSE', 'Biomarker', 'model']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "setup   = 'cond'\n",
    "if setup == 'forward': \n",
    "    samples = prior_samples \n",
    "elif setup == 'cond': \n",
    "    samples = cond_samples\n",
    "\n",
    "# model_dict = {'fomm_gated': 'FOMM PK-PD', 'fomm_linear': 'FOMM Linear', 'fomm_nl': 'FOMM NL', 'fomm_moe': 'FOMM MOE'}\n",
    "model_dict = {f'ssm-att-fold{fold}': 'SSM PK-PD', f'ssm-lin-fold{fold}': 'SSM Linear', 'nl-lin': 'SSM NL', 'moe-lin': 'SSM MOE'}\n",
    "\n",
    "for model in [f'ssm-att-fold{fold}', f'ssm-lin-fold{fold}']:\n",
    "    if model == 'nl-lin' or model == 'moe-lin':\n",
    "        continue\n",
    "    \n",
    "    if setup == 'forward':\n",
    "        Xv     = pt_numpy(X[:,1:T_forward])\n",
    "        Mv     = pt_numpy(M[:,1:T_forward])\n",
    "        pred   = samples[model][:,1:]\n",
    "    elif setup == 'cond':\n",
    "        Xv = pt_numpy(X[:,T_condition:T_condition+T_forward])\n",
    "        Mv = pt_numpy(M[:,T_condition:T_condition+T_forward])\n",
    "        pred = samples[model][:,-T_forward:]\n",
    "    diff_t = ((np.abs(pred-Xv))*Mv)\n",
    "    diff   = diff_t.sum(1); m = Mv.sum(1)\n",
    "    print(diff)\n",
    "    for feat, feat_name in enumerate(X_names): \n",
    "        mse_total = diff[:,feat]\n",
    "        mse_true  = mse_total[np.where(m[:,feat] != 0.)[0]]\n",
    "        for i in range(len(mse_true)): \n",
    "            df.loc[0 if pd.isnull(df.index.max()) else df.index.max() + 1] = [mse_true[i], \" \".join([f for f in feat_name.split(\"_\")]), f'{model_dict[model]}']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "a1 = sns.boxplot(ax=ax, x='Biomarker', y='MSE', hue='model',\n",
    "            data=df, palette='muted', linewidth=3)\n",
    "a1.set_ylim(-1,10)\n",
    "a1.set_ylabel('L1 Error', fontsize=35)\n",
    "a1.set_xlabel('Biomarker', fontsize=35)\n",
    "a1.tick_params(axis='x', labelsize=28)\n",
    "a1.tick_params(axis='y', labelsize=28)\n",
    "a1.legend(fontsize=30, loc='upper left')\n",
    "for item in a1.get_xticklabels():\n",
    "    item.set_rotation(55)\n",
    "fig.savefig('./plots/supp_fig2_bplot_cond2y_f6m.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_mins_max = {\n",
    "    'cbc_abs_neut':(2., 7.5,1/3.), # abs neutrophil count (3.67, 1.), (2.83, 4.51)\n",
    "    'chem_albumin':(34, 50,1/8.), # chemical albumin (43.62, 2.77), (41.30, 45.94)\n",
    "    'chem_bun':(2.5, 7.1,1/5.), #BUN # reference range, (4.8, 1.15)\n",
    "    'chem_calcium':(2.2, 2.7,2.), #Calcium, (2.45, 0.125)\n",
    "    'chem_creatinine':(66, 112,1/36.), # creatinine, (83., 24.85), (62.22, 103.77)\n",
    "    'chem_glucose':(3.9, 6.9,1/5.), # glucose, (4.91, 0.40), (4.58, 5.24)\n",
    "    'cbc_hemoglobin':(13., 17.,1), # hemoglobin (12.90, 15.64), (8.86, 1.02)\n",
    "    'chem_ldh':(2.33, 4.67,1/3.), #LDH, (3.5, 0.585)\n",
    "    'serum_m_protein':(0.1, 1.1, 1), # M protein (<3 g/dL is MGUS, any presence of protein is pathological); am just using the data mean/std for this, (0.85, 1.89)\n",
    "    'urine_24hr_m_protein':(0.0, 0.1, 1), # Urine M protein \n",
    "    'cbc_platelet':(150, 400,1/60.), # platelet count (206.42, 334.57), (270.5, 76.63)\n",
    "    'chem_totprot':(6, 8,1/6.), # total protein, (7, 0.5)\n",
    "    'urine_24hr_total_protein':(0, 0.23, 1), # \n",
    "    'cbc_wbc':(3, 10,1/4.), # WBC  (5.71, 8.44), (7.07, 1.63)\n",
    "    'serum_iga':(0.85, 4.99, 1.), # IgA, (2.92, 1.035)\n",
    "    'serum_igg':(6.10, 16.16,1/10.), # IgG, (11.13, 2.515)\n",
    "    'serum_igm':(0.35, 2.42,1), #IgM, (1.385, 0.518)\n",
    "    'serum_lambda':(0.57, 2.63, 1/2.), #serum lambda, (1.6, 0.515)\n",
    "    'serum_kappa':(.33, 1.94,1/8.), #serum kappa , (1.135, 0.403)\n",
    "    'serum_beta2_microglobulin':(0.7, 1.80, 1/3.), #serum_beta2_microglobulin,\n",
    "    'serum_c_reactive_protein':(0.0, 1., 1.) #serum_c_reactive_protein,\n",
    "}\n",
    "\n",
    "scaled_healthy_min_max = {}\n",
    "for k,v in healthy_mins_max.items(): \n",
    "    old_min, old_max, scale = v\n",
    "    new_min = (old_min - old_max)*scale\n",
    "    new_max = 0. \n",
    "    scaled_healthy_min_max[k] = (new_min, new_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify_by_nll(B, X, A, M, Y, CE, thr=20.):\n",
    "#     thr = 20.\n",
    "    model_loss = {}\n",
    "    for model in models: \n",
    "        loss = models[model].get_loss(B, X, A, M, Y, CE)\n",
    "        mloss = pt_numpy(loss[0])\n",
    "        print(model)\n",
    "        model_loss[model] = mloss \n",
    "    lin_loss = model_loss[f'ssm-lin-fold{fold}']; gated_loss = model_loss[f'ssm-att-fold{fold}']\n",
    "    diff = (lin_loss - gated_loss)\n",
    "    idxlist = np.where(diff >= thr)[0]\n",
    "    # gated_sub = gated_loss[idxlist]\n",
    "\n",
    "    return B[idxlist], X[idxlist], A[idxlist], M[idxlist], Y[idxlist], CE[idxlist]\n",
    "\n",
    "def stratify_by_lens(B, X, A, M, Y, CE, slen=20): \n",
    "    _, _, lens = get_masks(M)\n",
    "    return B[lens>slen], X[lens>slen], A[lens>slen], M[lens>slen], Y[lens>slen], CE[lens>slen]\n",
    "\n",
    "def stratify_by_line(B, X, A, M, Y, CE): \n",
    "    # filter out patients who don't have second or third line therapies \n",
    "    idxs = np.unique(np.where(pt_numpy(A)[...,-2:] == 1.)[0])\n",
    "    return B[idxs], X[idxs], A[idxs], M[idxs], Y[idxs], CE[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_loader   = models[f'ssm-att-fold{fold}'].load_helper('valid', device=device)\n",
    "(B, X, A, M, Y, CE) = data_loader.dataset.tensors\n",
    "\n",
    "T_forward  = 10; T_condition = 10\n",
    "B, X, A, M, Y, CE = stratify_by_nll(B, X, A, M, Y, CE, thr=20.)\n",
    "B, X, A, M, Y, CE = stratify_by_lens(B, X, A, M, Y, CE, slen=T_forward+T_condition)\n",
    "# B, X, A, M, Y, CE = stratify_by_line(B, X, A, M, Y, CE)\n",
    "print(B.shape)\n",
    "\n",
    "pf_samples   = {}\n",
    "cond_samples = {}\n",
    "prior_samples= {}\n",
    "nelbo, pf_nelbo, p_z_mu, q_z_mu, inp_x_post, inp_x = models[f'ssm-att-fold{fold}'].inspect(T_forward, T_condition, B, X, A, M, Y, CE, nsamples=3, eps=0.)\n",
    "_, pf_samples[f'ssm-att-fold{fold}'], _, _, cond_samples[f'ssm-att-fold{fold}'], prior_samples[f'ssm-att-fold{fold}'] = tuple([pt_numpy(k) for k in (nelbo, pf_nelbo, p_z_mu, q_z_mu, inp_x_post, inp_x)])\n",
    "nelbo, pf_nelbo, p_z_mu, q_z_mu, inp_x_post, inp_x = models[f'ssm-lin-fold{fold}'].inspect(T_forward, T_condition, B, X, A, M, Y, CE, nsamples=3, eps=0.)\n",
    "_, pf_samples[f'ssm-lin-fold{fold}'], _, _, cond_samples[f'ssm-lin-fold{fold}'], prior_samples[f'ssm-lin-fold{fold}'] = tuple([pt_numpy(k) for k in (nelbo, pf_nelbo, p_z_mu, q_z_mu, inp_x_post, inp_x)])\n",
    "\n",
    "data_cond= pt_numpy(X[:,:T_condition+T_forward,:])\n",
    "obs_cond = pt_numpy(M[:,:T_condition+T_forward,:])\n",
    "a_cond   = pt_numpy(A[:,:T_condition+T_forward,:])\n",
    "data_cond[obs_cond==0] = np.nan\n",
    "\n",
    "data_prior= pt_numpy(X[:,:T_forward,:])\n",
    "obs_prior = pt_numpy(M[:,:T_forward,:])\n",
    "a_prior   = pt_numpy(A[:,:T_forward,:])\n",
    "# print(data_prior[:,0,:].shape)\n",
    "# print(prior_samples[0.][:,0,:].shape)\n",
    "# assert data_prior[:,0,:].shape == prior_samples[0.][:,0,:].shape\n",
    "data_prior[obs_prior==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names_orig = mmdata[fold]['train']['feature_names_x']\n",
    "A_names = mmdata[fold]['train']['feature_names_a']\n",
    "B_names = mmdata[fold]['train']['feature_names']\n",
    "all_names = np.concatenate([X_names_orig, A_names, B_names],0)\n",
    "print (all_names.shape, X_names_orig.shape)\n",
    "X_names = [s.replace('_', ' ') for s in X_names_orig]\n",
    "print(B_names)\n",
    "print(X_names)\n",
    "print(A_names)\n",
    "print(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def plot_features_alt(plotlist, data, treat, X_names, A_names, group = 'serum', nplots = 3, xpush=1,ypush=1):\n",
    "    assert group in ['serum','cbc'],'bad group'\n",
    "    if group == 'cbc':\n",
    "        if nplots == 1:\n",
    "            fig, axgrid = plt.subplots(nplots,5,figsize=(20,5))\n",
    "            axgrid = axgrid.reshape(1, 5)\n",
    "        else:\n",
    "            fig, axgrid = plt.subplots(nplots,5,figsize=(20,10))\n",
    "        group_idx   = [3, 4, 6, 9, 7]\n",
    "    elif group == 'serum':\n",
    "        if nplots == 1:\n",
    "            fig, axgrid = plt.subplots(nplots,2,figsize=(9,5.5))\n",
    "            axgrid = axgrid.reshape(1, 2)\n",
    "        else:\n",
    "            fig, axgrid = plt.subplots(nplots,5,figsize=(20,10))\n",
    "#         group_idx   = [12, 13, 14, 15, 7]\n",
    "        group_idx   = [13,15]\n",
    "    else:\n",
    "        raise ValueError('bad setting for group')\n",
    "    formatting = {}\n",
    "    formatting[0] = ('--x','r')\n",
    "    formatting[1] = ('--o','k')\n",
    "    formatting[2] = ('--v','g')\n",
    "    formatting[3] = ('--^','b')\n",
    "    formatting[4] = ('--.','m')\n",
    "    \n",
    "    A_markers  = {}\n",
    "    A_markers['Bor'] = '>'\n",
    "    A_markers['Car'] = '<'\n",
    "    A_markers['Cyc'] = '^'\n",
    "    A_markers['Len'] = 'v'\n",
    "    A_markers['Dex'] = 'o'\n",
    "    axlist = axgrid.ravel()\n",
    "\n",
    "    from matplotlib.legend import Legend\n",
    "    lines = []; labels = []\n",
    "    \n",
    "    for j, ax in enumerate(axlist): \n",
    "        ctr= group_idx[j]\n",
    "        x  = np.arange(data.shape[1])\n",
    "        ax.scatter(x, data[0][:,ctr].astype('float'), s=64, label='Data')\n",
    "        for pltidx, (name, vals) in enumerate(plotlist):\n",
    "            # x = np.arange(vals.shape[1]) \n",
    "            ax.plot(x, vals[0][:,ctr], formatting[pltidx][0], label=name, color=formatting[pltidx][1], alpha = 0.5, markersize=8)\n",
    "#         if i==0:\n",
    "        ax.set_title(X_names[ctr], fontsize=25)\n",
    "        vmin, vmax = scaled_healthy_min_max[X_names_orig[ctr]]\n",
    "        ax.axhline(y=vmax, color='darkgreen', linestyle='--', alpha=0.6)\n",
    "        ax.axhline(y=vmin, color='darkgrey', linestyle='--', alpha=0.6)\n",
    "        ax.xaxis.set_ticks(np.arange(0, data.shape[1], 2))\n",
    "\n",
    "\n",
    "        ymax = ax.get_ylim()[1]+0.05\n",
    "        # Plot treatments\n",
    "#         import pdb; pdb.set_trace()\n",
    "        treat_i = treat[0]\n",
    "        for tidx in range(treat_i.shape[1]-1):\n",
    "            if A_names[tidx]=='local_clock' or 'line' in A_names[tidx]:\n",
    "                continue\n",
    "            tlist_x = []\n",
    "            tlist_y = []\n",
    "            for t in range(treat_i.shape[0]):\n",
    "                if treat_i[t, tidx] ==1:\n",
    "                    tlist_x.append(t)\n",
    "                    tlist_y.append(ymax+0.34*tidx)\n",
    "            l = ax.scatter(tlist_x, tlist_y, marker=A_markers[A_names[tidx]])\n",
    "            if j == 1:\n",
    "                lines.append(l); labels.append(A_names[tidx])\n",
    "        \n",
    "        lot1list_x = []; lot1list_y = []\n",
    "        lot2list_x = []; lot2list_y = []\n",
    "        lot3list_x = []; lot3list_y = []\n",
    "        for t in range(treat_i.shape[0]): \n",
    "            line = np.where(treat_i[t][-3:] == 1.)[0]+1\n",
    "            if line == 1: \n",
    "                lot1list_x.append(t); lot1list_y.append(ymax+0.1*treat_i.shape[1]-1)\n",
    "            elif line == 2: \n",
    "                lot2list_x.append(t); lot2list_y.append(ymax+0.1*treat_i.shape[1]-1)\n",
    "            elif line == 3: \n",
    "                lot3list_x.append(t); lot3list_y.append(ymax+0.1*treat_i.shape[1]-1)\n",
    "#                     ax.fill_between(tlist_x, np.array(tlist_y)+4, np.array(tlist_y)+6, color='darkred', alpha=0.7)\n",
    "        if j == 1: \n",
    "            if len(lot3list_x) != 0: \n",
    "                l = ax.fill_between(lot3list_x, np.array(lot3list_y)+.7,np.array(lot3list_y)+1., color='darkgreen', alpha=0.7)\n",
    "                lines.insert(0,l); labels.insert(0,'Line 3')\n",
    "            if len(lot2list_x) != 0: \n",
    "                l = ax.fill_between(lot2list_x, np.array(lot2list_y)+.7,np.array(lot2list_y)+1., color='darkblue', alpha=0.7)\n",
    "                lines.insert(0,l); labels.insert(0,'Line 2')\n",
    "            if len(lot1list_x) != 0: \n",
    "                l = ax.fill_between(lot1list_x, np.array(lot1list_y)+.7,np.array(lot1list_y)+1., color='darkred', alpha=0.7)\n",
    "                lines.insert(0,l); labels.insert(0,'Line 1')\n",
    "\n",
    "        ylims = ax.get_ylim()\n",
    "        if j==0:\n",
    "            ax.legend(loc='best',bbox_to_anchor=(-.3,.3),\n",
    "                      fancybox=True, shadow=True, ncol=1, fontsize = 25)\n",
    "        if j==0 or j == 1: \n",
    "            ax.set_xlabel('Time (per 2 months)', fontsize=25)\n",
    "        \n",
    "    leg = Legend(axlist[0], lines, labels,\n",
    "                 loc='best', frameon=True, fancybox = True, shadow=True, fontsize=25, bbox_to_anchor=(-.33,1.09))\n",
    "    axlist[0].add_artist(leg);\n",
    "    \n",
    "    plt.subplots_adjust(top=0.9, wspace=0.25)\n",
    "#     plt.xlabel('Time (per 2 months)', fontsize=25)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nplots = 1\n",
    "setup  = 'cond'\n",
    "idx    = 5\n",
    "idxlist = np.arange(prior_samples[f'ssm-att-fold{fold}'].shape[0])+idx\n",
    "\n",
    "if setup == 'forward':\n",
    "    l = [('Linear', prior_samples[f'ssm-lin-fold{fold}'][idx:])]\n",
    "    l += [(f'PK-PD', prior_samples[f'ssm-att-fold{fold}'][idx:])]\n",
    "    fig = plot_features_alt(l, data_prior[idx:], a_prior[idx:], X_names, A_names, group='serum', nplots = nplots, xpush=6.9, ypush=2)\n",
    "    fig = plot_features_alt(l, data_prior[idx:], a_prior[idx:], X_names, A_names, group='cbc', nplots = nplots, xpush=6.9, ypush=2)\n",
    "else:\n",
    "    l = [('Linear', cond_samples[f'ssm-lin-fold{fold}'][idx:])]\n",
    "    l += [(f'PK-PD', cond_samples[f'ssm-att-fold{fold}'][idx:])]\n",
    "    fig = plot_features_alt(l, data_cond[idx:], a_cond[idx:], X_names, A_names, group='serum', nplots = nplots, xpush=8)\n",
    "#     fig = plot_features_alt(l, data_cond[idx:], a_cond[idx:], X_names, A_names, group='cbc', nplots = nplots, xpush=8)\n",
    "# fig.suptitle('Lab for T = %d conditioned on patient %s baseline data'%(T_forward, ','.join([str(k) for k in idxlist[:nplots]])), fontsize=20)\n",
    "# fig.suptitle('Lab for T = %d conditioned on patient baseline data'%(T_forward), fontsize=20)\n",
    "fig.savefig('./plots/fold3_idx5_main_cond10_forw10_2markers.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent State Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_loader = models[f'ssm-att-fold{fold}'].load_helper('test', device=device)\n",
    "X_names_orig = mmdata[fold]['train']['feature_names_x']\n",
    "A_names = mmdata[fold]['train']['feature_names_a']\n",
    "B_names = mmdata[fold]['train']['feature_names']\n",
    "all_names = np.concatenate([X_names_orig, A_names, B_names],0)\n",
    "print (all_names.shape, X_names_orig.shape)\n",
    "X_names = [s.replace('_', ' ') for s in X_names_orig]\n",
    "print(B_names)\n",
    "print(X_names)\n",
    "print(A_names)\n",
    "print(all_names)\n",
    "\n",
    "bins   = np.array([10.,12.,19.])\n",
    "time   = [0, 4, 9, 14, 18,19, 24, 29]\n",
    "EI = ModelIntrospector(models[f'ssm-att-fold{fold}'], data_loader, [X_names, A_names, B_names])\n",
    "result_CEs, (y1,y2,y3) = EI.get_latent_tsne(bins, time=time, verbose=True)\n",
    "\n",
    "(B, X, A, M, Y, CE) = data_loader.dataset.tensors\n",
    "_, _, lens = get_masks(M)\n",
    "B, X, A, M, Y, CE  = B[lens>1], X[lens>1], A[lens>1], M[lens>1], Y[lens>1], CE[lens>1]\n",
    "Bn = pt_numpy(B); Xn = pt_numpy(X); Mn = pt_numpy(M); CEn = pt_numpy(CE); An = pt_numpy(A)\n",
    "Bn_obs = Bn[np.where(CEn==1)[0]]; Xn_obs = Xn[np.where(CEn==1)[0]]; Mn_obs = Mn[np.where(CEn==1)[0]]\n",
    "An_obs = An[np.where(CEn==1)[0]]\n",
    "a1 = np.where(An_obs[:,18,-3])[0]\n",
    "a2 = np.where(An_obs[:,18,-2])[0]\n",
    "a3 = np.where(An_obs[:,18,-1])[0]\n",
    "a4 = np.where((An_obs[:,18,-1]+An_obs[:,18,-2]+An_obs[:,18,-3]) == 0.)[0]\n",
    "\n",
    "for i in range(len(X_names)): \n",
    "    print(f'stats for {X_names[i]}')\n",
    "    print(f'no treatment average: {np.mean(Xn_obs[a4,18,i])}')\n",
    "    print(f'line 3 trt average: {np.mean(Xn_obs[a3,18,i])}')\n",
    "    print(f'line 2 trt average: {np.mean(Xn_obs[a2,18,i])}')\n",
    "    print(f'line 1 trt average: {np.mean(Xn_obs[a1,18,i])}')\n",
    "\n",
    "a1g3 = np.array([116,110,91,61,63,64,66,60,87])\n",
    "\n",
    "Yn = pt_numpy(Y)\n",
    "Yn_obs     = Yn[np.where(CEn==1)[0]]\n",
    "Yidx_obs   = np.where(Yn_obs==1)[1]\n",
    "\n",
    "fig, axlist   = plt.subplots(2,4,figsize=(18,9))\n",
    "ax = axlist.ravel()\n",
    "\n",
    "for i,t in enumerate(time):\n",
    "    result_CE = result_CEs[i]\n",
    "    bor = np.where(An_obs[:,t,1])[0]\n",
    "    car = np.where(An_obs[:,t,2])[0]\n",
    "    cyc = np.where(An_obs[:,t,3])[0]\n",
    "    dex = np.where(An_obs[:,t,4])[0]\n",
    "    lena = np.where(An_obs[:,t,5])[0]\n",
    "    \n",
    "    \n",
    "    a1 = np.where(An_obs[:,t,-3])[0]\n",
    "    a2 = np.where(An_obs[:,t,-2])[0]\n",
    "    a3 = np.where(An_obs[:,t,-1])[0]\n",
    "    a4 = np.where((An_obs[:,t,-1]+An_obs[:,t,-2]+An_obs[:,t,-3]) == 0.)[0]\n",
    "    a1g1= np.where(An_obs[:,t,-4]+An_obs[:,t,-3] == 2.)[0]\n",
    "    a1g2= np.where(An_obs[:,t,-4] == 0.)[0]\n",
    "    ax[i].set_title(f'T = {t}', fontsize=25)\n",
    "    \n",
    "    if t == 29: \n",
    "#         ax[i].scatter(result_CE[a1g1,0],result_CE[a1g1,1], label = 'LEN (line1)', s=36)\n",
    "#         ax[i].scatter(result_CE[a1g2,0],result_CE[a1g2,1], label = 'no LEN (line1)', s=36)\n",
    "        ax[i].scatter(result_CE[a1,0],result_CE[a1,1], label = 'line1', s=36)\n",
    "        ax[i].scatter(result_CE[a2,0],result_CE[a2,1], label = 'line2', s=36)\n",
    "        ax[i].scatter(result_CE[a3,0],result_CE[a3,1], label = 'line3plus', s=36)\n",
    "        ax[i].scatter(result_CE[a4,0],result_CE[a4,1], label = 'noRx', s=36)\n",
    "        ax[i].legend(loc='lower right', fontsize=15)\n",
    "    else: \n",
    "#         ax[i].scatter(result_CE[a1g1,0],result_CE[a1g1,1], s=36)\n",
    "#         ax[i].scatter(result_CE[a1g2,0],result_CE[a1g2,1], s=36)\n",
    "        ax[i].scatter(result_CE[a1,0],result_CE[a1,1], s=36)\n",
    "        ax[i].scatter(result_CE[a2,0],result_CE[a2,1], s=36)\n",
    "        ax[i].scatter(result_CE[a3,0],result_CE[a3,1], s=36)\n",
    "        ax[i].scatter(result_CE[a4,0],result_CE[a4,1], s=36)\n",
    "\n",
    "# plt.savefig('./plots/latent_tsne_len_time.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axlist   = plt.subplots(1,2,figsize=(10,5.3))\n",
    "ax    = axlist.ravel()\n",
    "times = [4,18]\n",
    "idxs  = [1,4]\n",
    "for i,t in enumerate(times):\n",
    "    result_CE = result_CEs[idxs[i]]\n",
    "    a1 = np.where(An_obs[:,t,-3])[0]\n",
    "    a2 = np.where(An_obs[:,t,-2])[0]\n",
    "    a3 = np.where(An_obs[:,t,-1])[0]\n",
    "    a4 = np.where((An_obs[:,t,-1]+An_obs[:,t,-2]+An_obs[:,t,-3]) == 0.)[0]\n",
    "    a1g1= np.where(An_obs[:,t,-4]+An_obs[:,t,-3] == 2.)[0]\n",
    "    a1g2= np.where(An_obs[:,t,-4] == 0.)[0]\n",
    "    if i == 0: \n",
    "        ax[i].set_title(f'8 Months', fontsize=25)\n",
    "    if i == 1: \n",
    "        ax[i].set_title(f'36 Months', fontsize=25)\n",
    "    if i == 1: \n",
    "        ax[i].scatter(result_CE[a1,0],result_CE[a1,1], label = 'line1', s=36)\n",
    "        ax[i].scatter(result_CE[a2,0],result_CE[a2,1], label = 'line2', s=36)\n",
    "        ax[i].scatter(result_CE[a3,0],result_CE[a3,1], label = 'line3plus', s=36)\n",
    "        ax[i].scatter(result_CE[a4,0],result_CE[a4,1], label = 'noRx', s=36)\n",
    "        ax[i].legend(loc='upper left', bbox_to_anchor=(-1.2,1.), fontsize=15)\n",
    "    else: \n",
    "        ax[i].scatter(result_CE[a1,0],result_CE[a1,1], s=36)\n",
    "        ax[i].scatter(result_CE[a2,0],result_CE[a2,1], s=36)\n",
    "        ax[i].scatter(result_CE[a3,0],result_CE[a3,1], s=36)\n",
    "        ax[i].scatter(result_CE[a4,0],result_CE[a4,1], s=36)\n",
    "\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig('./plots/latent_tsne_2time.pdf',bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
